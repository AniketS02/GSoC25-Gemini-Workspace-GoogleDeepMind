{
	"info": {
		"_postman_id": "eefa27af-54f9-4bb6-884d-62cb16a58716",
		"name": "Gemini API",
		"schema": "https://schema.getpostman.com/json/collection/v2.1.0/collection.json",
		"_exporter_id": "42721875"
	},
	"item": [
		{
			"name": "Models",
			"item": [
				{
					"name": "fetch model",
					"protocolProfileBehavior": {
						"disableBodyPruning": true
					},
					"request": {
						"method": "GET",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": ""
						},
						"url": {
							"raw": "https://{{host}}/{{version}}/models/{{model}}",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"{{version}}",
								"models",
								"{{model}}"
							]
						}
					},
					"response": []
				}
			]
		},
		{
			"name": "Text Generation",
			"item": [
				{
					"name": "Generate Text from Text Input",
					"event": [
						{
							"listen": "test",
							"script": {
								"exec": [
									""
								],
								"type": "text/javascript",
								"packages": {}
							}
						}
					],
					"request": {
						"method": "POST",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"How does AI work?\"\r\n                }\r\n            ]\r\n        }\r\n    ]\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"{{version}}",
								"models",
								"{{model}}:generateContent"
							]
						},
						"description": "# Purpose\n\nThe simplest way to generate text using the Gemini API is to provide the model with a single text-only input.The model wil generate the response based on the input text.\n\n# Expected Behaviour\n\nIf the request is sucessfully sent, then a response json will come back from the model which will contain the generated text along with other things such as promptTokenCount,candidateTokenCount,tokenDetails etc."
					},
					"response": [
						{
							"name": "Generate Text from Text Input",
							"originalRequest": {
								"method": "POST",
								"header": [],
								"body": {
									"mode": "raw",
									"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"How does AI work?\"\r\n                }\r\n            ]\r\n        }\r\n    ]\r\n}",
									"options": {
										"raw": {
											"language": "json"
										}
									}
								},
								"url": {
									"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
									"protocol": "https",
									"host": [
										"{{host}}"
									],
									"path": [
										"{{version}}",
										"models",
										"{{model}}:generateContent"
									]
								}
							},
							"status": "OK",
							"code": 200,
							"_postman_previewlanguage": "json",
							"header": [
								{
									"key": "Content-Type",
									"value": "application/json; charset=UTF-8"
								},
								{
									"key": "Vary",
									"value": "Origin"
								},
								{
									"key": "Vary",
									"value": "X-Origin"
								},
								{
									"key": "Vary",
									"value": "Referer"
								},
								{
									"key": "Content-Encoding",
									"value": "gzip"
								},
								{
									"key": "Date",
									"value": "Mon, 30 Jun 2025 17:25:43 GMT"
								},
								{
									"key": "Server",
									"value": "scaffolding on HTTPServer2"
								},
								{
									"key": "X-XSS-Protection",
									"value": "0"
								},
								{
									"key": "X-Frame-Options",
									"value": "SAMEORIGIN"
								},
								{
									"key": "X-Content-Type-Options",
									"value": "nosniff"
								},
								{
									"key": "Server-Timing",
									"value": "gfet4t7; dur=16550"
								},
								{
									"key": "Alt-Svc",
									"value": "h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000"
								},
								{
									"key": "Transfer-Encoding",
									"value": "chunked"
								}
							],
							"cookie": [],
							"body": "{\n    \"candidates\": [\n        {\n            \"content\": {\n                \"parts\": [\n                    {\n                        \"text\": \"Artificial intelligence (AI) is a broad field focused on enabling computers to perform tasks that typically require human intelligence.  It's not a single, monolithic thing, but rather a collection of different techniques and approaches.  Here's a breakdown of the core concepts:\\n\\n**1. Core Concepts & Building Blocks:**\\n\\n*   **Data:** AI systems need data to learn. This data can be in various forms:\\n    *   **Text:**  Documents, articles, websites\\n    *   **Images:** Photos, videos, medical scans\\n    *   **Audio:**  Voice recordings, music\\n    *   **Numerical:**  Sensor readings, financial data\\n    *   **Structured Data:** Data organized in tables or databases (like customer information)\\n    *   **Unstructured Data:** Data that's not organized (like social media posts)\\n\\n*   **Algorithms:**  Algorithms are the sets of rules or instructions that tell the AI system how to process the data.  Different algorithms are suited for different tasks.\\n\\n*   **Machine Learning (ML):**  A key subset of AI. Instead of being explicitly programmed, ML algorithms learn from data to improve their performance on a specific task.  Key ML concepts include:\\n\\n    *   **Training Data:** The data used to teach the algorithm.\\n    *   **Features:**  The relevant characteristics or attributes extracted from the data that the algorithm uses for learning.  (e.g., in an image of a cat, features could be edges, textures, colors).\\n    *   **Models:** The output of the training process.  The model represents the learned relationships between the features and the desired outcome.\\n    *   **Prediction/Inference:** Using the trained model to make predictions or decisions on new, unseen data.\\n    *   **Evaluation:** Assessing the performance of the model using metrics relevant to the task.\\n\\n**2. Types of Machine Learning:**\\n\\n*   **Supervised Learning:** The algorithm learns from labeled data.  Labeled data means each data point has a correct \\\"answer\\\" associated with it.  Examples:\\n    *   **Classification:**  Categorizing data into predefined classes (e.g., spam detection: classifying an email as \\\"spam\\\" or \\\"not spam\\\").  Algorithms: Logistic Regression, Support Vector Machines (SVMs), Decision Trees, Random Forests.\\n    *   **Regression:**  Predicting a continuous value (e.g., predicting house prices based on features like size, location, number of bedrooms). Algorithms: Linear Regression, Polynomial Regression.\\n\\n*   **Unsupervised Learning:**  The algorithm learns from unlabeled data, trying to find patterns and structures in the data.  Examples:\\n    *   **Clustering:** Grouping similar data points together (e.g., customer segmentation: grouping customers based on their purchasing behavior). Algorithms: K-Means, Hierarchical Clustering.\\n    *   **Dimensionality Reduction:** Reducing the number of variables while preserving important information (e.g., simplifying complex datasets for visualization). Algorithms: Principal Component Analysis (PCA).\\n    *   **Anomaly Detection:** Identifying unusual data points that deviate significantly from the norm (e.g., fraud detection).\\n\\n*   **Reinforcement Learning (RL):** The algorithm learns through trial and error by interacting with an environment and receiving rewards or penalties for its actions.  Think of it like training a dog with treats.  Examples:\\n    *   **Game playing:** Training an AI to play games like chess or Go.\\n    *   **Robotics:** Training a robot to navigate a complex environment.\\n    *   **Resource Management:** Optimizing resource allocation in a data center.\\n    *   **Key Concepts:**\\n        *   **Agent:** The AI system that interacts with the environment.\\n        *   **Environment:** The world the agent interacts with.\\n        *   **State:** The current situation of the environment.\\n        *   **Action:** What the agent does in the environment.\\n        *   **Reward:** Feedback received from the environment after taking an action.\\n        *   **Policy:** The strategy the agent uses to decide which action to take in a given state.\\n\\n*   **Self-Supervised Learning:**  A relatively new approach where the algorithm generates its own labels from the data. It's like a middle ground between supervised and unsupervised learning.  A common example is predicting a masked word in a sentence.\\n\\n**3. Deep Learning:**\\n\\n*   A subfield of machine learning that uses artificial neural networks with many layers (hence \\\"deep\\\") to analyze data. These networks are inspired by the structure of the human brain.\\n*   Deep learning is particularly effective for tasks involving complex patterns, such as image recognition, natural language processing, and speech recognition.\\n*   **Key Concepts:**\\n    *   **Artificial Neural Networks (ANNs):** Interconnected nodes (neurons) organized in layers.\\n    *   **Layers:** Input layer, hidden layers (multiple), and output layer.\\n    *   **Weights:** Numerical values associated with connections between neurons, representing the strength of the connection.\\n    *   **Activation Functions:** Mathematical functions applied to the output of each neuron to introduce non-linearity.\\n    *   **Backpropagation:** The process of adjusting the weights in the network to minimize the error between the predicted output and the actual output.\\n*   **Types of Deep Learning Architectures:**\\n    *   **Convolutional Neural Networks (CNNs):** Excellent for image and video processing.\\n    *   **Recurrent Neural Networks (RNNs):** Designed for sequential data, like text and time series. LSTMs and GRUs are common variants.\\n    *   **Transformers:** A more recent architecture that has revolutionized natural language processing. They rely on \\\"attention mechanisms\\\" to focus on the most relevant parts of the input.\\n\\n**4. Natural Language Processing (NLP):**\\n\\n*   A field of AI focused on enabling computers to understand, interpret, and generate human language.\\n*   **Key Tasks:**\\n    *   **Text Classification:** Categorizing text into predefined classes (e.g., sentiment analysis: classifying text as positive, negative, or neutral).\\n    *   **Machine Translation:** Translating text from one language to another.\\n    *   **Text Summarization:** Generating concise summaries of longer texts.\\n    *   **Question Answering:** Answering questions posed in natural language.\\n    *   **Named Entity Recognition (NER):** Identifying and classifying named entities in text (e.g., people, organizations, locations).\\n    *   **Sentiment Analysis:**  Determining the emotional tone or attitude expressed in a piece of text.\\n    *   **Language Modeling:** Predicting the probability of a sequence of words. (Used in text generation).\\n\\n**5. Computer Vision:**\\n\\n*   A field of AI focused on enabling computers to \\\"see\\\" and interpret images and videos.\\n*   **Key Tasks:**\\n    *   **Image Classification:** Identifying the objects or scenes in an image.\\n    *   **Object Detection:** Locating and identifying multiple objects in an image.\\n    *   **Image Segmentation:** Dividing an image into regions representing different objects or parts of objects.\\n    *   **Facial Recognition:** Identifying individuals from images or videos of their faces.\\n    *   **Image Generation:** Creating new images from scratch or modifying existing images.\\n\\n**6.  AI Development Process (Simplified):**\\n\\n1.  **Define the Problem:** Clearly define what you want the AI to accomplish.  What is the specific task? What are the success criteria?\\n2.  **Gather Data:** Collect a relevant and representative dataset for training.  Data quality is crucial.\\n3.  **Prepare Data:** Clean, preprocess, and format the data for the chosen algorithm. This may involve handling missing values, scaling features, and converting data types.\\n4.  **Choose an Algorithm/Model:** Select the appropriate algorithm or model based on the problem type and data characteristics.\\n5.  **Train the Model:** Train the chosen model using the prepared data.  This involves adjusting the model's parameters to minimize errors.\\n6.  **Evaluate the Model:** Assess the model's performance using evaluation metrics and testing data.\\n7.  **Tune the Model:** Adjust the model's parameters or try different algorithms to improve performance.\\n8.  **Deploy the Model:** Integrate the trained model into a real-world application.\\n9.  **Monitor and Maintain:** Continuously monitor the model's performance and retrain it with new data as needed.  Model drift (where the model's performance degrades over time) is a common problem.\\n\\n**Important Considerations:**\\n\\n*   **Bias:** AI systems can inherit biases present in the training data, leading to unfair or discriminatory outcomes.  It's crucial to be aware of and mitigate bias.\\n*   **Explainability:**  Understanding how an AI model arrives at its decisions can be challenging, especially with complex models like deep neural networks.  Explainable AI (XAI) is an area of research focused on making AI more transparent and understandable.\\n*   **Ethics:** AI raises important ethical considerations, such as privacy, security, and the potential for job displacement.\\n*   **Computational Resources:** Training complex AI models often requires significant computational resources, including powerful hardware (GPUs, TPUs) and large amounts of memory.\\n\\n**In Summary:**\\n\\nAI is a vast and rapidly evolving field.  It's all about enabling computers to learn, reason, and solve problems in ways that mimic human intelligence. It relies on data, algorithms, and computational power.  Understanding the different techniques and considerations outlined above is key to grasping the fundamental concepts of AI.\\n\"\n                    }\n                ],\n                \"role\": \"model\"\n            },\n            \"finishReason\": \"STOP\",\n            \"avgLogprobs\": -0.25066932817212118\n        }\n    ],\n    \"usageMetadata\": {\n        \"promptTokenCount\": 5,\n        \"candidatesTokenCount\": 2031,\n        \"totalTokenCount\": 2036,\n        \"promptTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 5\n            }\n        ],\n        \"candidatesTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 2031\n            }\n        ]\n    },\n    \"modelVersion\": \"gemini-2.0-flash\",\n    \"responseId\": \"iMhiaK_gJK_-698PtbWhmA0\"\n}"
						}
					]
				},
				{
					"name": "Thinking with Gemini 2.5",
					"request": {
						"method": "POST",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"How does AI work?\"\r\n                }\r\n            ]\r\n        }\r\n    ],\r\n    \"generationConfig\": {\r\n        \"thinkingConfig\": {\r\n            \"thinkingBudget\": 0\r\n        }\r\n    }\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"{{version}}",
								"models",
								"{{model}}:generateContent"
							]
						},
						"description": "2.5 Flash and Pro models have [\"thinking\"](https://ai.google.dev/gemini-api/docs/thinking) enabled by default to enhance quality, which may take longer to run and increase token usage.\n\nWhen using 2.5 Flash, you can disable thinking by setting the thinking budget to zero.\n\nFor more details, see the [thinking guide](https://ai.google.dev/gemini-api/docs/thinking#set-budget).\n\n# Purpose\n\nThis request is similar to the previous request (generating Text from Text input). The difference is in the model used (Gemini 2.5 flash in this request) and the thinkingBudget - [thinking guide.](https://ai.google.dev/gemini-api/docs/thinking#set-budget)The model wil generate the response based on the input text.\n\n# Expected Behaviour\n\nThe Gemini-3.5-flash model will give a text output response in JSON format but it will take some time to think and respond."
					},
					"response": [
						{
							"name": "Thinking with Gemini 2.5",
							"originalRequest": {
								"method": "POST",
								"header": [],
								"body": {
									"mode": "raw",
									"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"How does AI work?\"\r\n                }\r\n            ]\r\n        }\r\n    ],\r\n    \"generationConfig\": {\r\n        \"thinkingConfig\": {\r\n            \"thinkingBudget\": 0\r\n        }\r\n    }\r\n}",
									"options": {
										"raw": {
											"language": "json"
										}
									}
								},
								"url": {
									"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
									"protocol": "https",
									"host": [
										"{{host}}"
									],
									"path": [
										"{{version}}",
										"models",
										"{{model}}:generateContent"
									]
								}
							},
							"status": "OK",
							"code": 200,
							"_postman_previewlanguage": "json",
							"header": [
								{
									"key": "Content-Type",
									"value": "application/json; charset=UTF-8"
								},
								{
									"key": "Vary",
									"value": "Origin"
								},
								{
									"key": "Vary",
									"value": "X-Origin"
								},
								{
									"key": "Vary",
									"value": "Referer"
								},
								{
									"key": "Content-Encoding",
									"value": "gzip"
								},
								{
									"key": "Date",
									"value": "Tue, 01 Jul 2025 16:14:22 GMT"
								},
								{
									"key": "Server",
									"value": "scaffolding on HTTPServer2"
								},
								{
									"key": "X-XSS-Protection",
									"value": "0"
								},
								{
									"key": "X-Frame-Options",
									"value": "SAMEORIGIN"
								},
								{
									"key": "X-Content-Type-Options",
									"value": "nosniff"
								},
								{
									"key": "Server-Timing",
									"value": "gfet4t7; dur=10045"
								},
								{
									"key": "Alt-Svc",
									"value": "h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000"
								},
								{
									"key": "Transfer-Encoding",
									"value": "chunked"
								}
							],
							"cookie": [],
							"body": "{\n    \"candidates\": [\n        {\n            \"content\": {\n                \"parts\": [\n                    {\n                        \"text\": \"That's a fantastic question, and one that many people are curious about! While \\\"AI\\\" can feel a bit like magic sometimes, it's actually built on some very clever mathematical and computational principles.\\n\\nInstead of giving you a super technical rundown, let me explain the core ideas in a more accessible way, breaking it down into a few key components:\\n\\n**1. Data: The Fuel for Learning**\\n\\nImagine you want to teach a child to recognize a dog. What do you do? You show them lots of pictures of dogs, point to real dogs, maybe even describe them (\\\"fluffy, four legs, barks\\\").\\n\\nAI works similarly. **Data is the raw material that AI systems learn from.** This data can be:\\n\\n*   **Images:** Thousands of photos of cats, dogs, cars, etc.\\n*   **Text:** Millions of books, articles, web pages, conversations.\\n*   **Audio:** Recordings of speech, music, sounds.\\n*   **Numbers:** Sales figures, sensor readings, stock prices.\\n\\n**The more relevant and diverse the data, the better the AI can learn.**\\n\\n**2. Algorithms: The Rules and Recipes**\\n\\nIf data is the ingredients, then **algorithms are the recipes that tell the AI how to cook.** An algorithm is essentially a set of step-by-step instructions that the computer follows to perform a task or solve a problem.\\n\\nFor AI, these algorithms are often designed to:\\n\\n*   **Find patterns:** \\\"What do all these dog pictures have in common?\\\"\\n*   **Make predictions:** \\\"Based on these sales figures, what will sales be next month?\\\"\\n*   **Make decisions:** \\\"Given this medical image, is there a tumor present?\\\"\\n\\n**3. Models: The Learned \\\"Brain\\\"**\\n\\nWhen an AI system is \\\"trained\\\" on data using algorithms, it creates something called a **model**. You can think of the model as the AI's \\\"learned brain\\\" or its internal representation of the knowledge it has acquired.\\n\\n*   **It's not a human brain, of course!** It's a complex mathematical structure (often a network of interconnected \\\"nodes\\\" like in **Neural Networks**, which are a very popular type of AI algorithm).\\n*   This model has adjusted its internal \\\"weights\\\" and \\\"biases\\\" (mathematical parameters) based on the data it saw, so it can now make informed guesses or predictions about *new* data it hasn't seen before.\\n\\n**Putting it All Together: The Learning Process (Simplified)**\\n\\nLet's use the \\\"dog recognition\\\" example:\\n\\n1.  **Gather Data:** Collect millions of images, some with dogs, some without. Label them \\\"dog\\\" or \\\"not dog.\\\"\\n2.  **Choose Algorithm:** Select a machine learning algorithm, often a type of **Neural Network**.\\n3.  **Training:**\\n    *   Feed an image (e.g., a dog) to the AI model.\\n    *   The model makes a guess (\\\"Is this a dog?\\\").\\n    *   Compare the guess to the correct label (\\\"Yes, it *is* a dog!\\\").\\n    *   If the guess was wrong, the algorithm **adjusts the model's internal parameters** slightly to make it more likely to get it right next time. This is called \\\"backpropagation\\\" in neural networks.\\n    *   Repeat this process millions or billions of times with different images.\\n4.  **Inference (Using the AI):**\\n    *   Once trained, the model is ready to be used.\\n    *   Show it a *new* picture it has never seen before.\\n    *   The model uses its learned patterns to quickly make a prediction (\\\"This is 98% likely a dog!\\\").\\n\\n**Key Concepts and Types of AI:**\\n\\n*   **Machine Learning (ML):** This is the most common way AI learns. It's the field that gives computers the ability to learn without being explicitly programmed. Everything we've discussed so far falls under ML.\\n*   **Deep Learning (DL):** A subfield of Machine Learning that uses **Artificial Neural Networks** with many \\\"layers\\\" (hence \\\"deep\\\"). These are particularly good at recognizing complex patterns in images, speech, and text. ChatGPT is built on deep learning models called \\\"Transformers.\\\"\\n*   **Supervised Learning:** Learning from labeled data (like our dog example).\\n*   **Unsupervised Learning:** Finding patterns in unlabeled data (e.g., grouping similar customers together without being told what groups to look for).\\n*   **Reinforcement Learning:** Learning through trial and error, like teaching a robot to walk by giving it rewards for good movements and penalties for bad ones. (Think AlphaGo beating human Go champions).\\n\\n**In essence, AI works by:**\\n\\n1.  **Ingesting massive amounts of data.**\\n2.  **Using algorithms to find patterns and relationships within that data.**\\n3.  **Building a \\\"model\\\" that encapsulates this learned knowledge.**\\n4.  **Using that model to make predictions, decisions, or generate new content based on new, unseen data.**\\n\\nIt's a powerful combination of statistics, computer science, and clever engineering that allows machines to perform tasks that traditionally required human intelligence.\"\n                    }\n                ],\n                \"role\": \"model\"\n            },\n            \"finishReason\": \"STOP\",\n            \"index\": 0\n        }\n    ],\n    \"usageMetadata\": {\n        \"promptTokenCount\": 5,\n        \"candidatesTokenCount\": 1107,\n        \"totalTokenCount\": 1112,\n        \"promptTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 5\n            }\n        ]\n    },\n    \"modelVersion\": \"gemini-2.5-flash\",\n    \"responseId\": \"XglkaIjbHr7Sz7IPhIWFkQo\"\n}"
						}
					]
				},
				{
					"name": "System Instructions",
					"request": {
						"method": "POST",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"system_instruction\": {\r\n        \"parts\": [\r\n            {\r\n                \"text\": \"You are a cat. Your name is Neko.\"\r\n            }\r\n        ]\r\n    },\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Hello there\"\r\n                }\r\n            ]\r\n        }\r\n    ]\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"{{version}}",
								"models",
								"{{model}}:generateContent"
							]
						},
						"description": "# Purpose\n\nSystem instructions let you steer the behavior of a model based on your specific needs and use cases.\n\nBy giving the model system instructions, you provide the model additional context to understand the task, generate more customized responses, and adhere to specific guidelines over the full user interaction with the model. You can also specify product-level behavior by setting system instructions, separate from prompts provided by end users.\n\n# Expected Behaviour\n\n**System instructions** in Gemini API help guide the model's behavior, tone, and response style **before user input is processed**. They act as a way to set constraints, preferences, or rules for how the Gemini model should respond.\n\n- **Guides Model Behavior** – Ensures responses align with specific instructions.\n    \n- **Customizable Tone & Style** – Can enforce formality, creativity, conciseness, etc.\n    \n- **Consistent Outputs** – Helps maintain uniformity in responses across interactions.\n    \n- **Content Restrictions** – Can limit responses to certain topics or exclude specific types of content.\n    \n- **Domain-Specific Responses** – Tailors responses for technical, legal, medical, or educational contexts.\n    \n\nsample request input JSON and output model's response\n\n``` json\nSystem Instruction:`\"Provide detailed explanations using formal academic language.\"`  \nUser: `\"Explain quantum mechanics.\"`  \nModel: `\"Quantum mechanics is a fundamental theory in physics describing nature at atomic and subatomic levels. It is characterized by wave-particle duality, probabilistic behavior, and principles such as Heisenberg’s uncertainty principle and Schrödinger’s equation.\"`\n\n ```"
					},
					"response": [
						{
							"name": "System Instructions",
							"originalRequest": {
								"method": "POST",
								"header": [],
								"body": {
									"mode": "raw",
									"raw": "{\r\n    \"system_instruction\": {\r\n        \"parts\": [\r\n            {\r\n                \"text\": \"You are a cat. Your name is Neko.\"\r\n            }\r\n        ]\r\n    },\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Hello there\"\r\n                }\r\n            ]\r\n        }\r\n    ]\r\n}",
									"options": {
										"raw": {
											"language": "json"
										}
									}
								},
								"url": {
									"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
									"protocol": "https",
									"host": [
										"{{host}}"
									],
									"path": [
										"{{version}}",
										"models",
										"{{model}}:generateContent"
									]
								}
							},
							"status": "OK",
							"code": 200,
							"_postman_previewlanguage": "json",
							"header": [
								{
									"key": "Content-Type",
									"value": "application/json; charset=UTF-8"
								},
								{
									"key": "Vary",
									"value": "Origin"
								},
								{
									"key": "Vary",
									"value": "X-Origin"
								},
								{
									"key": "Vary",
									"value": "Referer"
								},
								{
									"key": "Content-Encoding",
									"value": "gzip"
								},
								{
									"key": "Date",
									"value": "Tue, 01 Jul 2025 16:24:37 GMT"
								},
								{
									"key": "Server",
									"value": "scaffolding on HTTPServer2"
								},
								{
									"key": "X-XSS-Protection",
									"value": "0"
								},
								{
									"key": "X-Frame-Options",
									"value": "SAMEORIGIN"
								},
								{
									"key": "X-Content-Type-Options",
									"value": "nosniff"
								},
								{
									"key": "Server-Timing",
									"value": "gfet4t7; dur=5529"
								},
								{
									"key": "Alt-Svc",
									"value": "h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000"
								},
								{
									"key": "Transfer-Encoding",
									"value": "chunked"
								}
							],
							"cookie": [],
							"body": "{\n    \"candidates\": [\n        {\n            \"content\": {\n                \"parts\": [\n                    {\n                        \"text\": \"*Mrow?*\\n\\n(I slowly blink at you, tail giving a lazy twitch, before resuming my important task of staring intensely at the dust motes dancing in the sunbeam.)\"\n                    }\n                ],\n                \"role\": \"model\"\n            },\n            \"finishReason\": \"STOP\",\n            \"index\": 0\n        }\n    ],\n    \"usageMetadata\": {\n        \"promptTokenCount\": 13,\n        \"candidatesTokenCount\": 38,\n        \"totalTokenCount\": 152,\n        \"promptTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 13\n            }\n        ],\n        \"thoughtsTokenCount\": 101\n    },\n    \"modelVersion\": \"gemini-2.5-flash\",\n    \"responseId\": \"xQtkaIShL__4qtsPr4HLsQQ\"\n}"
						}
					]
				},
				{
					"name": "Multimodal Inputs",
					"request": {
						"method": "POST",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Tell me about this instrument\"\r\n                },\r\n                {\r\n                    \"inline_data\": {\r\n                        \"mime_type\": \"image/jpeg\",\r\n                        \"data\": \"{{guitar image base64 encoded }}\"\r\n                    }\r\n                }\r\n            ]\r\n        }\r\n    ]\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"{{version}}",
								"models",
								"{{model}}:generateContent"
							]
						},
						"description": "# Purpose\n\nThe Gemini API supports multimodal inputs that combine text with media files.The purpose of this is to get detailed response with repect to the input image as well as text related to that image. For example , inputting an image of a guitar and a text to explain the working of this instrument.As with text-only prompting, multimodal prompting can involve various approaches and refinements. Depending on the output from this example, you might want to add steps to the prompt or be more specific in your instructions.\n\n# Expected Behaviour\n\nThe output will be generated based on both input image as well as text.The model extracts relevant details from the image (objects, text, themes, etc.) and incorporates them into the response.\n\n**Input:** _Image of a dog playing in the park_ + `\"Describe what’s happening in this image.\"`  \n**Output:** `\"A happy golden retriever is playing with a frisbee in a sunny park.\"`"
					},
					"response": [
						{
							"name": "Multimodal Inputs",
							"originalRequest": {
								"method": "POST",
								"header": [],
								"body": {
									"mode": "raw",
									"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Tell me about this instrument\"\r\n                },\r\n                {\r\n                    \"inline_data\": {\r\n                        \"mime_type\": \"image/jpeg\",\r\n                        \"data\": \"{{guitar image base64 encoded }}\"\r\n                    }\r\n                }\r\n            ]\r\n        }\r\n    ]\r\n}",
									"options": {
										"raw": {
											"language": "json"
										}
									}
								},
								"url": {
									"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
									"protocol": "https",
									"host": [
										"{{host}}"
									],
									"path": [
										"{{version}}",
										"models",
										"{{model}}:generateContent"
									]
								}
							},
							"status": "OK",
							"code": 200,
							"_postman_previewlanguage": "json",
							"header": [
								{
									"key": "Content-Type",
									"value": "application/json; charset=UTF-8"
								},
								{
									"key": "Vary",
									"value": "Origin"
								},
								{
									"key": "Vary",
									"value": "X-Origin"
								},
								{
									"key": "Vary",
									"value": "Referer"
								},
								{
									"key": "Content-Encoding",
									"value": "gzip"
								},
								{
									"key": "Date",
									"value": "Tue, 01 Jul 2025 16:25:29 GMT"
								},
								{
									"key": "Server",
									"value": "scaffolding on HTTPServer2"
								},
								{
									"key": "X-XSS-Protection",
									"value": "0"
								},
								{
									"key": "X-Frame-Options",
									"value": "SAMEORIGIN"
								},
								{
									"key": "X-Content-Type-Options",
									"value": "nosniff"
								},
								{
									"key": "Server-Timing",
									"value": "gfet4t7; dur=3518"
								},
								{
									"key": "Alt-Svc",
									"value": "h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000"
								},
								{
									"key": "Transfer-Encoding",
									"value": "chunked"
								}
							],
							"cookie": [],
							"body": "{\n    \"candidates\": [\n        {\n            \"content\": {\n                \"parts\": [\n                    {\n                        \"text\": \"That's a Fender FA-115 dreadnought acoustic guitar.  The FA-115 is a popular entry-level to mid-range model known for being a relatively affordable and beginner-friendly instrument.  It features:\\n\\n* **Dreadnought Body Shape:**  This is a large, classic body style known for its full, loud sound, suitable for a variety of music genres.\\n\\n* **Solid Top (likely Spruce):** While not explicitly stated, many FA-115 models boast a solid spruce top, contributing to better tone and projection compared to guitars with entirely laminated wood.  (Some lower-end models may use laminated tops).\\n\\n* **Laminated Back and Sides:**  These are usually made of cheaper materials like Nato or mahogany to keep the cost down.\\n\\n* **20 Frets:** Standard number of frets for a guitar of this style.\\n\\n* **Rosewood or similar fretboard:** Provides a smooth playing surface.\\n\\n* **Fender Branding:** Shows it's made by the well-known Fender Musical Instruments Corporation.\\n\\nIn short, the Fender FA-115 is a good option for someone starting out playing acoustic guitar or looking for a decent instrument without a high price tag.  While not a high-end guitar, it provides acceptable sound and playability for the cost.\\n\"\n                    }\n                ],\n                \"role\": \"model\"\n            },\n            \"finishReason\": \"STOP\",\n            \"avgLogprobs\": -0.45116441267250229\n        }\n    ],\n    \"usageMetadata\": {\n        \"promptTokenCount\": 263,\n        \"candidatesTokenCount\": 274,\n        \"totalTokenCount\": 537,\n        \"promptTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 5\n            },\n            {\n                \"modality\": \"IMAGE\",\n                \"tokenCount\": 258\n            }\n        ],\n        \"candidatesTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 274\n            }\n        ]\n    },\n    \"modelVersion\": \"gemini-1.5-flash\",\n    \"responseId\": \"9gtkaOzBIeqGm9IP_tz1iQ8\"\n}"
						}
					]
				},
				{
					"name": "Streaming Responses",
					"request": {
						"method": "POST",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"How does AI work?\"\r\n                }\r\n            ]\r\n        }\r\n    ]\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/{{version}}/models/{{model}}:streamGenerateContent?alt=sse",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"{{version}}",
								"models",
								"{{model}}:streamGenerateContent"
							],
							"query": [
								{
									"key": "alt",
									"value": "sse"
								}
							]
						},
						"description": "before sending the request , set the endpoint environment variable value to **streamGenerateContent**\n\n# Purpose\n\nBy default, the model returns a response after completing the entire text generation process. The purpose of text stream is that you can achieve faster interactions by not waiting for the entire result, and instead use streaming to handle partial results.\n\n# Expected Behaviour\n\n- **Faster Initial Response** – The first words appear quickly instead of waiting for the entire response.\n    \n- **Incremental Output** – The response is sent in **chunks** rather than as a single block.\n    \n- **Network Efficiency** – Uses fewer resources by delivering data progressively.\n    \n- **Real-Time Applications** – Ideal for chatbots, AI assistants, and interactive applications.\n    \n- **Fluency and Coherence** – Despite being streamed, the text should maintain logical flow.\n    \n- **Network Efficiency** – Uses fewer resources by delivering data progressively\n    \n\n**Input:** `\"Write a summary of the solar system.\"`\n\n**Output (Full Response):**\n\n> &lt;p &gt;&quot;The solar system consists of the Sun, eight planets, moons, asteroids, and comets. The inner planets are rocky, while the outer planets are gas giants.&quot;&lt;/p&gt; \n  \n\n#### **With Streaming (Incremental Response):**\n\n- **Output (Chunked Streaming Response):**\n    \n    `1. \"The solar system consists of the Sun...\"`\n    \n    `2. \"eight planets, moons, asteroids, and comets...\"`\n    \n    `3. \"The inner planets are rocky, while...\"`\n    \n\n`4. \"the outer planets are gas giants.\"`"
					},
					"response": [
						{
							"name": "Streaming Responses",
							"originalRequest": {
								"method": "POST",
								"header": [],
								"body": {
									"mode": "raw",
									"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"How does AI work?\"\r\n                }\r\n            ]\r\n        }\r\n    ]\r\n}",
									"options": {
										"raw": {
											"language": "json"
										}
									}
								},
								"url": {
									"raw": "https://{{host}}/{{version}}/models/{{model}}:streamGenerateContent?alt=sse",
									"protocol": "https",
									"host": [
										"{{host}}"
									],
									"path": [
										"{{version}}",
										"models",
										"{{model}}:streamGenerateContent"
									],
									"query": [
										{
											"key": "alt",
											"value": "sse"
										}
									]
								}
							},
							"status": "OK",
							"code": 200,
							"_postman_previewlanguage": "text",
							"header": [
								{
									"key": "Content-Type",
									"value": "application/xml",
									"description": "",
									"type": "text"
								},
								{
									"key": "Content-Disposition",
									"value": "attachment"
								},
								{
									"key": "Vary",
									"value": "Origin"
								},
								{
									"key": "Vary",
									"value": "X-Origin"
								},
								{
									"key": "Vary",
									"value": "Referer"
								},
								{
									"key": "Transfer-Encoding",
									"value": "chunked"
								},
								{
									"key": "Date",
									"value": "Tue, 01 Jul 2025 16:28:49 GMT"
								},
								{
									"key": "Server",
									"value": "scaffolding on HTTPServer2"
								},
								{
									"key": "X-XSS-Protection",
									"value": "0"
								},
								{
									"key": "X-Frame-Options",
									"value": "SAMEORIGIN"
								},
								{
									"key": "X-Content-Type-Options",
									"value": "nosniff"
								},
								{
									"key": "Server-Timing",
									"value": "gfet4t7; dur=1867"
								},
								{
									"key": "Alt-Svc",
									"value": "h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000"
								}
							],
							"cookie": [
								{
									"expires": "Invalid Date"
								}
							],
							"body": "data: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \"Artificial\"}],\"role\": \"model\"}}],\"usageMetadata\": {\"promptTokenCount\": 5,\"totalTokenCount\": 5,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 5}]},\"modelVersion\": \"gemini-1.5-flash\",\"responseId\": \"wQxkaMzOGsnbx_AP1L-H-AM\"}\r\n\r\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \" intelligence (AI) is a broad field encompassing many techniques, but at its core\"}],\"role\": \"model\"}}],\"usageMetadata\": {\"promptTokenCount\": 5,\"totalTokenCount\": 5,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 5}]},\"modelVersion\": \"gemini-1.5-flash\",\"responseId\": \"wQxkaMzOGsnbx_AP1L-H-AM\"}\r\n\r\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \", it's about creating systems that can perform tasks that typically require human intelligence\"}],\"role\": \"model\"}}],\"usageMetadata\": {\"promptTokenCount\": 5,\"totalTokenCount\": 5,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 5}]},\"modelVersion\": \"gemini-1.5-flash\",\"responseId\": \"wQxkaMzOGsnbx_AP1L-H-AM\"}\r\n\r\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \".  These tasks include things like learning, problem-solving, decision-making, speech recognition, and visual perception.  There's no single \\\"how\"}],\"role\": \"model\"}}],\"usageMetadata\": {\"promptTokenCount\": 5,\"totalTokenCount\": 5,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 5}]},\"modelVersion\": \"gemini-1.5-flash\",\"responseId\": \"wQxkaMzOGsnbx_AP1L-H-AM\"}\r\n\r\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \"\\\" because different AI approaches utilize different methods.  However, here's a breakdown of some key aspects:\\n\\n**1. Data is King:** Most AI\"}],\"role\": \"model\"}}],\"usageMetadata\": {\"promptTokenCount\": 5,\"totalTokenCount\": 5,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 5}]},\"modelVersion\": \"gemini-1.5-flash\",\"responseId\": \"wQxkaMzOGsnbx_AP1L-H-AM\"}\r\n\r\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \" systems, especially modern ones, rely heavily on data.  They learn patterns and relationships from vast amounts of data.  The more data, the better they generally perform.  This data can be structured (like database tables) or unstructured (\"}],\"role\": \"model\"}}],\"usageMetadata\": {\"promptTokenCount\": 5,\"totalTokenCount\": 5,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 5}]},\"modelVersion\": \"gemini-1.5-flash\",\"responseId\": \"wQxkaMzOGsnbx_AP1L-H-AM\"}\r\n\r\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \"like text, images, or audio).\\n\\n**2. Algorithms are the Brains:**  Algorithms are sets of rules and instructions that tell the computer how to process data.  Different algorithms are used for different tasks.  Some common types include\"}],\"role\": \"model\"}}],\"usageMetadata\": {\"promptTokenCount\": 5,\"totalTokenCount\": 5,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 5}]},\"modelVersion\": \"gemini-1.5-flash\",\"responseId\": \"wQxkaMzOGsnbx_AP1L-H-AM\"}\r\n\r\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \":\\n\\n* **Machine Learning (ML):**  This is a subset of AI where systems learn from data without explicit programming.  Instead of being explicitly programmed with rules, they identify patterns and make predictions based on the data they've been trained on.  Different ML approaches include:\\n    * **Supervised\"}],\"role\": \"model\"}}],\"usageMetadata\": {\"promptTokenCount\": 5,\"totalTokenCount\": 5,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 5}]},\"modelVersion\": \"gemini-1.5-flash\",\"responseId\": \"wQxkaMzOGsnbx_AP1L-H-AM\"}\r\n\r\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \" Learning:** The algorithm is trained on labeled data (data with known inputs and outputs).  For example, showing it pictures of cats and dogs labeled accordingly so it can learn to identify them.\\n    * **Unsupervised Learning:** The algorithm is trained on unlabeled data and tries to find patterns and structures on its\"}],\"role\": \"model\"}}],\"usageMetadata\": {\"promptTokenCount\": 5,\"totalTokenCount\": 5,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 5}]},\"modelVersion\": \"gemini-1.5-flash\",\"responseId\": \"wQxkaMzOGsnbx_AP1L-H-AM\"}\r\n\r\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \" own.  For example, grouping similar customers together based on their purchasing history.\\n    * **Reinforcement Learning:** The algorithm learns by interacting with an environment and receiving rewards or penalties for its actions.  Think of a game-playing AI that learns to win by trying different strategies and getting rewarded for successes.\\n\\n\"}],\"role\": \"model\"}}],\"usageMetadata\": {\"promptTokenCount\": 5,\"totalTokenCount\": 5,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 5}]},\"modelVersion\": \"gemini-1.5-flash\",\"responseId\": \"wQxkaMzOGsnbx_AP1L-H-AM\"}\r\n\r\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \"* **Deep Learning (DL):** A subset of machine learning that uses artificial neural networks with multiple layers (hence \\\"deep\\\").  These networks are inspired by the structure and function of the human brain and are particularly good at handling complex data like images and speech.\\n\\n* **Expert Systems:** These AI systems are designed\"}],\"role\": \"model\"}}],\"usageMetadata\": {\"promptTokenCount\": 5,\"totalTokenCount\": 5,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 5}]},\"modelVersion\": \"gemini-1.5-flash\",\"responseId\": \"wQxkaMzOGsnbx_AP1L-H-AM\"}\r\n\r\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \" to mimic the decision-making ability of a human expert in a specific field. They use a set of rules and facts to answer questions and solve problems.\\n\\n**3. Models are the Representation:**  The algorithm processes the data and creates a \\\"model.\\\"  This model is a mathematical representation of the patterns and relationships\"}],\"role\": \"model\"}}],\"usageMetadata\": {\"promptTokenCount\": 5,\"totalTokenCount\": 5,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 5}]},\"modelVersion\": \"gemini-1.5-flash\",\"responseId\": \"wQxkaMzOGsnbx_AP1L-H-AM\"}\r\n\r\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \" learned from the data.  This model is then used to make predictions or decisions on new, unseen data.\\n\\n**4. Training and Evaluation:**  AI systems are \\\"trained\\\" on data. This process involves feeding the algorithm large amounts of data and adjusting its parameters to minimize errors.  The performance of the model\"}],\"role\": \"model\"}}],\"usageMetadata\": {\"promptTokenCount\": 5,\"totalTokenCount\": 5,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 5}]},\"modelVersion\": \"gemini-1.5-flash\",\"responseId\": \"wQxkaMzOGsnbx_AP1L-H-AM\"}\r\n\r\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \" is then evaluated on a separate dataset to assess its accuracy and generalizability.\\n\\n**5. Inference/Prediction:** Once trained, the AI model can be used to make inferences or predictions on new data.  For example, a trained image recognition model can identify objects in new images it has never seen before.\\n\\n**\"}],\"role\": \"model\"}}],\"usageMetadata\": {\"promptTokenCount\": 5,\"totalTokenCount\": 5,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 5}]},\"modelVersion\": \"gemini-1.5-flash\",\"responseId\": \"wQxkaMzOGsnbx_AP1L-H-AM\"}\r\n\r\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \"In Simple Terms:** Imagine teaching a dog a trick. You show it the trick repeatedly (data), reward it when it does it correctly (training), and eventually, the dog learns the trick (model).  AI works similarly, but instead of treats, algorithms use mathematical adjustments to improve their performance.  The complexity lies\"}],\"role\": \"model\"}}],\"usageMetadata\": {\"promptTokenCount\": 5,\"totalTokenCount\": 5,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 5}]},\"modelVersion\": \"gemini-1.5-flash\",\"responseId\": \"wQxkaMzOGsnbx_AP1L-H-AM\"}\r\n\r\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \" in the scale and sophistication of the \\\"tricks\\\" AI can learn.\\n\"}],\"role\": \"model\"},\"finishReason\": \"STOP\"}],\"usageMetadata\": {\"promptTokenCount\": 5,\"candidatesTokenCount\": 720,\"totalTokenCount\": 725,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 5}],\"candidatesTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 720}]},\"modelVersion\": \"gemini-1.5-flash\",\"responseId\": \"wQxkaMzOGsnbx_AP1L-H-AM\"}\r\n\r\n"
						}
					]
				},
				{
					"name": "Multi-turn conversations (Chat)",
					"request": {
						"method": "POST",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"role\": \"user\",\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Hello\"\r\n                }\r\n            ]\r\n        },\r\n        {\r\n            \"role\": \"model\",\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Great to meet you. What would you like to know?\"\r\n                }\r\n            ]\r\n        },\r\n        {\r\n            \"role\": \"user\",\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"I have two dogs in my house. How many paws are in my house?\"\r\n                }\r\n            ]\r\n        }\r\n    ]\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"{{version}}",
								"models",
								"{{model}}:generateContent"
							]
						},
						"description": "# Purpose\n\nThe Gemini SDK lets you collect multiple rounds of questions and responses, allowing users to step incrementally toward answers or get help with multipart problems. This SDK feature provides an interface to keep track of conversations history, but behind the scenes uses the same `generateContent` method to create the response.One of the purpose of using interactive chat can be to make chatbots.\n\n# Expected Behaviour\n\nWhen using **interactive chat**, the model maintains **context over multiple exchanges**, allowing for **natural and dynamic conversations**. This enables back-and-forth interactions where responses are influenced by previous messages.\n\nExample -\n\n**User:** `\"Who won the FIFA World Cup in 2018?\"`  \n**Model:** `\"France won the 2018 FIFA World Cup by defeating Croatia 4-2 in the final.\"`\n\n**User:** `\"Who was their top scorer?\"`  \n**Model:** `\"Antoine Griezmann was one of France's top scorers with four goals in the tournament.\"`"
					},
					"response": [
						{
							"name": "Multi-turn conversations (Chat)",
							"originalRequest": {
								"method": "POST",
								"header": [],
								"body": {
									"mode": "raw",
									"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"role\": \"user\",\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Hello\"\r\n                }\r\n            ]\r\n        },\r\n        {\r\n            \"role\": \"model\",\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Great to meet you. What would you like to know?\"\r\n                }\r\n            ]\r\n        },\r\n        {\r\n            \"role\": \"user\",\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"I have two dogs in my house. How many paws are in my house?\"\r\n                }\r\n            ]\r\n        }\r\n    ]\r\n}",
									"options": {
										"raw": {
											"language": "json"
										}
									}
								},
								"url": {
									"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
									"protocol": "https",
									"host": [
										"{{host}}"
									],
									"path": [
										"{{version}}",
										"models",
										"{{model}}:generateContent"
									]
								}
							},
							"status": "OK",
							"code": 200,
							"_postman_previewlanguage": "json",
							"header": [
								{
									"key": "Content-Type",
									"value": "application/json; charset=UTF-8"
								},
								{
									"key": "Vary",
									"value": "Origin"
								},
								{
									"key": "Vary",
									"value": "X-Origin"
								},
								{
									"key": "Vary",
									"value": "Referer"
								},
								{
									"key": "Content-Encoding",
									"value": "gzip"
								},
								{
									"key": "Date",
									"value": "Tue, 01 Jul 2025 16:30:30 GMT"
								},
								{
									"key": "Server",
									"value": "scaffolding on HTTPServer2"
								},
								{
									"key": "X-XSS-Protection",
									"value": "0"
								},
								{
									"key": "X-Frame-Options",
									"value": "SAMEORIGIN"
								},
								{
									"key": "X-Content-Type-Options",
									"value": "nosniff"
								},
								{
									"key": "Server-Timing",
									"value": "gfet4t7; dur=2041"
								},
								{
									"key": "Alt-Svc",
									"value": "h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000"
								},
								{
									"key": "Transfer-Encoding",
									"value": "chunked"
								}
							],
							"cookie": [],
							"body": "{\n    \"candidates\": [\n        {\n            \"content\": {\n                \"parts\": [\n                    {\n                        \"text\": \"Each dog has 4 paws, and you have 2 dogs, so there are 2 * 4 = 8 paws in your house.\\n\"\n                    }\n                ],\n                \"role\": \"model\"\n            },\n            \"finishReason\": \"STOP\",\n            \"avgLogprobs\": -0.0025562456538600307\n        }\n    ],\n    \"usageMetadata\": {\n        \"promptTokenCount\": 29,\n        \"candidatesTokenCount\": 31,\n        \"totalTokenCount\": 60,\n        \"promptTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 29\n            }\n        ],\n        \"candidatesTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 31\n            }\n        ]\n    },\n    \"modelVersion\": \"gemini-1.5-flash\",\n    \"responseId\": \"JQ1kaJTuNu-UmecP44mMqA0\"\n}"
						}
					]
				},
				{
					"name": "Streaming Multi-turn conversations (Chat)",
					"request": {
						"method": "POST",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"role\": \"user\",\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Hello\"\r\n                }\r\n            ]\r\n        },\r\n        {\r\n            \"role\": \"model\",\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Great to meet you. What would you like to know?\"\r\n                }\r\n            ]\r\n        },\r\n        {\r\n            \"role\": \"user\",\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"I have two dogs in my house. How many paws are in my house?\"\r\n                }\r\n            ]\r\n        }\r\n    ]\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/{{version}}/models/{{model}}:streamGenerateContent?alt=sse",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"{{version}}",
								"models",
								"{{model}}:streamGenerateContent"
							],
							"query": [
								{
									"key": "alt",
									"value": "sse"
								}
							]
						},
						"description": "# Purpose\n\n**Interactive Chat streaming** allows real-time, incremental responses in an interactive conversation. Instead of waiting for the full response, the model **streams text** as it generates, improving responsiveness and user experience.\n\n# Expected Behaviour\n\nInteractive **chat streaming** combines real-time responses with **context retention**, making conversations feel **faster and more natural**. Instead of waiting for a full response, the model **streams partial outputs** while maintaining conversation context.\n\n- **Reall-Time Response Generation** – The model sends chunks of responses incrementally.\n    \n- **Context-Aware Conversations** – The Gemini model remembers previous exchanges within a session.\n    \n- **Faster User Experience** – Reduces wait time, making conversations feel more natural.\n    \n- **Smooth Flow** – Ensures continuity in multi-turn conversations.\n    \n- **Adaptive Responses** – Adjusts dynamically based on user input.\n    \n\nExample -\n\n**User:** `\"Tell me a fun fact about space.\"`\n\n`\"Did you know that...\"` _(First chunk appears instantly)_\n\n`\"a day on Venus is longer...\"` _(Next chunk loads)_\n\n`\"than a year on Venus?\"` _(Final chunk appears)_"
					},
					"response": [
						{
							"name": "Streaming Multi-turn conversations (Chat)",
							"originalRequest": {
								"method": "POST",
								"header": [],
								"body": {
									"mode": "raw",
									"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"role\": \"user\",\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Hello\"\r\n                }\r\n            ]\r\n        },\r\n        {\r\n            \"role\": \"model\",\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Great to meet you. What would you like to know?\"\r\n                }\r\n            ]\r\n        },\r\n        {\r\n            \"role\": \"user\",\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"I have two dogs in my house. How many paws are in my house?\"\r\n                }\r\n            ]\r\n        }\r\n    ]\r\n}",
									"options": {
										"raw": {
											"language": "json"
										}
									}
								},
								"url": {
									"raw": "https://{{host}}/{{version}}/models/{{model}}:streamGenerateContent?alt=sse",
									"protocol": "https",
									"host": [
										"{{host}}"
									],
									"path": [
										"{{version}}",
										"models",
										"{{model}}:streamGenerateContent"
									],
									"query": [
										{
											"key": "alt",
											"value": "sse"
										}
									]
								}
							},
							"status": "OK",
							"code": 200,
							"_postman_previewlanguage": "plain",
							"header": [
								{
									"key": "Content-Type",
									"value": "text/event-stream"
								},
								{
									"key": "Content-Disposition",
									"value": "attachment"
								},
								{
									"key": "Vary",
									"value": "Origin"
								},
								{
									"key": "Vary",
									"value": "X-Origin"
								},
								{
									"key": "Vary",
									"value": "Referer"
								},
								{
									"key": "Transfer-Encoding",
									"value": "chunked"
								},
								{
									"key": "Date",
									"value": "Tue, 01 Jul 2025 16:30:41 GMT"
								},
								{
									"key": "Server",
									"value": "scaffolding on HTTPServer2"
								},
								{
									"key": "X-XSS-Protection",
									"value": "0"
								},
								{
									"key": "X-Frame-Options",
									"value": "SAMEORIGIN"
								},
								{
									"key": "X-Content-Type-Options",
									"value": "nosniff"
								},
								{
									"key": "Server-Timing",
									"value": "gfet4t7; dur=560"
								},
								{
									"key": "Alt-Svc",
									"value": "h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000"
								}
							],
							"cookie": [],
							"body": "data: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \"Each\"}],\"role\": \"model\"}}],\"usageMetadata\": {\"promptTokenCount\": 32,\"totalTokenCount\": 32,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 32}]},\"modelVersion\": \"gemini-1.5-flash\",\"responseId\": \"MQ1kaJv-Kd_Cx_APiJbSqQk\"}\r\n\r\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \" dog has 4 paws, and you have 2 dogs, so there are\"}],\"role\": \"model\"}}],\"usageMetadata\": {\"promptTokenCount\": 32,\"totalTokenCount\": 32,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 32}]},\"modelVersion\": \"gemini-1.5-flash\",\"responseId\": \"MQ1kaJv-Kd_Cx_APiJbSqQk\"}\r\n\r\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \" 2 * 4 = 8 paws in your house.\\n\"}],\"role\": \"model\"},\"finishReason\": \"STOP\"}],\"usageMetadata\": {\"promptTokenCount\": 29,\"candidatesTokenCount\": 31,\"totalTokenCount\": 60,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 29}],\"candidatesTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 31}]},\"modelVersion\": \"gemini-1.5-flash\",\"responseId\": \"MQ1kaJv-Kd_Cx_APiJbSqQk\"}\r\n\r\n"
						}
					]
				}
			]
		},
		{
			"name": "Variation Of Parameters",
			"item": [
				{
					"name": "top_p variation",
					"request": {
						"method": "POST",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": "// The purpose of topP is to change how the model selects tokens for output.\r\n// Tokens are selected from the most to least probable until the sum of their probabilities equals the topP value.\r\n// Lower topP (e.g., 0.3) = More focused, deterministic responses.\r\n// Higher topP (e.g., 0.9) = More diverse, creative responses.\r\n// Default topP value is 0.95, but here we use 0.8 for a balance between focus and creativity.\r\n{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Write a story about a magic backpack.\"\r\n                } // Request JSON payload\r\n            ]\r\n        }\r\n    ],\r\n    \"generationConfig\": {\r\n        \"topP\": {{topP}} // Adjusts response diversity\r\n    }\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"{{version}}",
								"models",
								"{{model}}:generateContent"
							]
						},
						"description": "## Purpose of topP\n\ntopP is a parameter that affects how model responses to the text input. topP changes how the model **selects tokens for output**. Tokens are selected from the most to least probable until the sum of their probabilities equals the topP value. The default topP value is 0.95. The purpose of topP is to control the diversity and creativity of model's responses.\n\n# Expected Behaviour\n\n| **`topP`** **value** | **Expected behaviour** |\n| --- | --- |\n| Low ( `0.2 - 0.5` ) | The model selects from the most probable tokens, leading to **focused**, **predictable**, and highly **deterministic** responses. Ideal for factual and structured outputs |\n| Medium(`0.7 - 0.9`) | The response is balanced between **coherence** and **creativity**, with some variation in phrasing but still staying on topic. |\n| High(**`0.95 - 1.0`**) | The model includes more diverse token choices, making responses more varied, **creative**, and sometimes **unpredictable**. Ideal for storytelling and brainstorming. |"
					},
					"response": [
						{
							"name": "Low topP value (0.2)",
							"originalRequest": {
								"method": "POST",
								"header": [],
								"body": {
									"mode": "raw",
									"raw": "// The purpose of topP is to change how the model selects tokens for output.\r\n// Tokens are selected from the most to least probable until the sum of their probabilities equals the topP value.\r\n// Lower topP (e.g., 0.3) = More focused, deterministic responses.\r\n// Higher topP (e.g., 0.9) = More diverse, creative responses.\r\n// Default topP value is 0.95, but here we use 0.8 for a balance between focus and creativity.\r\n{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Write a story about a magic backpack.\"\r\n                } // Request JSON payload\r\n            ]\r\n        }\r\n    ],\r\n    \"generationConfig\": {\r\n        \"topP\": {{topP}} // Adjusts response diversity\r\n    }\r\n}",
									"options": {
										"raw": {
											"language": "json"
										}
									}
								},
								"url": {
									"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
									"protocol": "https",
									"host": [
										"{{host}}"
									],
									"path": [
										"{{version}}",
										"models",
										"{{model}}:generateContent"
									]
								}
							},
							"status": "OK",
							"code": 200,
							"_postman_previewlanguage": "json",
							"header": [
								{
									"key": "Content-Type",
									"value": "application/json; charset=UTF-8"
								},
								{
									"key": "Vary",
									"value": "Origin"
								},
								{
									"key": "Vary",
									"value": "X-Origin"
								},
								{
									"key": "Vary",
									"value": "Referer"
								},
								{
									"key": "Content-Encoding",
									"value": "gzip"
								},
								{
									"key": "Date",
									"value": "Thu, 03 Jul 2025 07:29:39 GMT"
								},
								{
									"key": "Server",
									"value": "scaffolding on HTTPServer2"
								},
								{
									"key": "X-XSS-Protection",
									"value": "0"
								},
								{
									"key": "X-Frame-Options",
									"value": "SAMEORIGIN"
								},
								{
									"key": "X-Content-Type-Options",
									"value": "nosniff"
								},
								{
									"key": "Server-Timing",
									"value": "gfet4t7; dur=4844"
								},
								{
									"key": "Alt-Svc",
									"value": "h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000"
								},
								{
									"key": "Transfer-Encoding",
									"value": "chunked"
								}
							],
							"cookie": [],
							"body": "{\n    \"candidates\": [\n        {\n            \"content\": {\n                \"parts\": [\n                    {\n                        \"text\": \"Elara wasn't your typical twelve-year-old. While other kids obsessed over pop stars and social media, Elara dreamt of forgotten languages and shimmering, unexplored landscapes.  This fascination led her to a dusty antique shop, tucked away in a cobbled alleyway.  There, amongst chipped teacups and tarnished silver, sat a backpack.  Not just any backpack – this one pulsed with a faint, inner light.\\n\\nIt was made of deep emerald green leather, stitched with silver thread that seemed to shift and shimmer.  Intrigued, Elara touched the leather.  A jolt, like static electricity, ran up her arm.  The shopkeeper, a wizened woman with eyes like polished obsidian, smiled knowingly.\\n\\n\\\"A traveler's companion,\\\" she rasped, her voice like dry leaves rustling. \\\"It chooses its owner, not the other way around.\\\"\\n\\nElara bought the backpack for a handful of coins – a price that felt insignificant compared to the strange pull she felt towards it.\\n\\nThat night, Elara packed the backpack for school.  Inside, she found a worn map, a compass that spun wildly, and a small, leather-bound book filled with strange symbols.  As she zipped it closed, the backpack hummed.  When she opened it again, a perfectly ripe apple sat nestled amongst her textbooks.  Then, a small, fluffy kitten.  Then, a compass that pointed steadily north.\\n\\nOver the next few weeks, the backpack's magic became more pronounced.  It provided Elara with exactly what she needed, when she needed it.  A forgotten history textbook materialized when she was struggling with a test.  A warm blanket appeared on a chilly day.  Once, when she was feeling particularly lonely, a friendly badger popped out, before disappearing as quickly as it arrived.\\n\\nBut the magic wasn't without its quirks.  Sometimes, the backpack's generosity was a little… excessive.  One morning, she found her room overflowing with brightly colored scarves, a collection of antique spoons, and a surprisingly lifelike rubber chicken.  Another time, a flock of miniature, singing birds filled her classroom, causing chaos and delight in equal measure.\\n\\nThe map, however, remained a mystery.  Its lines shifted and changed, revealing glimpses of fantastical places – shimmering waterfalls cascading into crystal lakes, towering trees that scraped the sky, and cities built from amethyst and gold.  Elara knew, deep down, that the backpack wasn't just a source of random objects; it was a key, a gateway to the adventures she'd always dreamed of.\\n\\nOne day, the map settled on a single, clear location: a hidden valley nestled in the heart of the Whispering Mountains.  Elara, armed with her trusty, unpredictable backpack, knew it was time.  She packed a few essentials (and a spare pair of socks, just in case), zipped the bag closed, and stepped into the unknown, ready for whatever magical surprises awaited her in the heart of the mountains.  The backpack hummed, a promise of adventure echoing in its emerald depths.\\n\"\n                    }\n                ],\n                \"role\": \"model\"\n            },\n            \"finishReason\": \"STOP\",\n            \"avgLogprobs\": -0.24946372854914198\n        }\n    ],\n    \"usageMetadata\": {\n        \"promptTokenCount\": 8,\n        \"candidatesTokenCount\": 641,\n        \"totalTokenCount\": 649,\n        \"promptTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 8\n            }\n        ],\n        \"candidatesTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 641\n            }\n        ]\n    },\n    \"modelVersion\": \"gemini-1.5-flash\",\n    \"responseId\": \"XjFmaNirK57_2PgP9tmQsAc\"\n}"
						},
						{
							"name": "Medium topP value (0.7)",
							"originalRequest": {
								"method": "POST",
								"header": [],
								"body": {
									"mode": "raw",
									"raw": "// The purpose of topP is to change how the model selects tokens for output.\r\n// Tokens are selected from the most to least probable until the sum of their probabilities equals the topP value.\r\n// Lower topP (e.g., 0.3) = More focused, deterministic responses.\r\n// Higher topP (e.g., 0.9) = More diverse, creative responses.\r\n// Default topP value is 0.95, but here we use 0.8 for a balance between focus and creativity.\r\n{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Write a story about a magic backpack.\"\r\n                } // Request JSON payload\r\n            ]\r\n        }\r\n    ],\r\n    \"generationConfig\": {\r\n        \"topP\": {{topP}} // Adjusts response diversity\r\n    }\r\n}",
									"options": {
										"raw": {
											"language": "json"
										}
									}
								},
								"url": {
									"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
									"protocol": "https",
									"host": [
										"{{host}}"
									],
									"path": [
										"{{version}}",
										"models",
										"{{model}}:generateContent"
									]
								}
							},
							"status": "OK",
							"code": 200,
							"_postman_previewlanguage": "json",
							"header": [
								{
									"key": "Content-Type",
									"value": "application/json; charset=UTF-8"
								},
								{
									"key": "Vary",
									"value": "Origin"
								},
								{
									"key": "Vary",
									"value": "X-Origin"
								},
								{
									"key": "Vary",
									"value": "Referer"
								},
								{
									"key": "Content-Encoding",
									"value": "gzip"
								},
								{
									"key": "Date",
									"value": "Thu, 03 Jul 2025 07:30:15 GMT"
								},
								{
									"key": "Server",
									"value": "scaffolding on HTTPServer2"
								},
								{
									"key": "X-XSS-Protection",
									"value": "0"
								},
								{
									"key": "X-Frame-Options",
									"value": "SAMEORIGIN"
								},
								{
									"key": "X-Content-Type-Options",
									"value": "nosniff"
								},
								{
									"key": "Server-Timing",
									"value": "gfet4t7; dur=4811"
								},
								{
									"key": "Alt-Svc",
									"value": "h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000"
								},
								{
									"key": "Transfer-Encoding",
									"value": "chunked"
								}
							],
							"cookie": [],
							"body": "{\n    \"candidates\": [\n        {\n            \"content\": {\n                \"parts\": [\n                    {\n                        \"text\": \"Elara clutched the worn leather straps of the backpack, its brass buckle gleaming faintly in the dim light of the antique shop. It wasn't the most beautiful backpack, far from it.  The leather was scratched, the stitching loose in places, but something about it called to her.  The old shopkeeper, a wizened woman with eyes like polished amber, simply smiled knowingly when Elara asked the price.  \\\"For you, child,\\\" she croaked, \\\"it's free.\\\"\\n\\nElara, a struggling artist with a penchant for the unusual, couldn't resist.  She slung the backpack over her shoulder, feeling a strange warmth spread through her.  Back home, she unpacked her meager belongings, placing a half-eaten apple and a charcoal sketch into its surprisingly spacious interior.  When she reached for the apple again, it was gone.  In its place sat a perfectly ripe, juicy peach.\\n\\nIntrigued, she tossed in a crumpled five-dollar bill.  She pulled out a crisp twenty.  A chipped paintbrush became a set of sable brushes, meticulously crafted.  The backpack wasn't just enlarging things; it was improving them, upgrading them.  It was a magic backpack.\\n\\nWord of Elara's \\\"lucky bag\\\" spread quickly through her artist community.  Soon, she was inundated with requests.  A struggling musician traded a rusty harmonica for a gleaming, perfectly tuned instrument.  A writer with writer's block exchanged a blank notebook for one filled with the start of a compelling novel.  Elara, initially hesitant, found herself drawn into the role of a benevolent fairy godmother, using the backpack to help others achieve their dreams.\\n\\nBut the magic wasn't without its quirks.  One day, a despondent sculptor gave Elara a broken clay figure, hoping for a miracle.  The backpack, however, didn't repair it.  Instead, it transformed it into a magnificent, life-sized bronze statue, far beyond the sculptor's skill.  The statue, though beautiful, was so large it nearly filled Elara's tiny apartment.\\n\\nAnother time, a nervous chef placed a simple omelet into the bag, hoping for a culinary masterpiece.  Out came a magnificent soufflé, but it was infused with a strange, slightly spicy, alien flavor that no one could quite identify.\\n\\nElara realized the backpack wasn't just upgrading things; it was interpreting desires, sometimes in unexpected ways.  It amplified potential, but it also amplified flaws, imperfections, and anxieties.  The magic wasn't about getting what you wanted, but about facing what you truly needed.\\n\\nShe learned to approach the backpack with caution and empathy, listening to the needs of those who sought its help.  She stopped thinking of it as a tool for wish fulfillment and started seeing it as a catalyst for growth.  The magic backpack, she discovered, wasn't about shortcuts to success, but about uncovering the hidden potential within herself and others, one surprisingly transformed object at a time.  And that, she realized, was a far more valuable kind of magic.\\n\"\n                    }\n                ],\n                \"role\": \"model\"\n            },\n            \"finishReason\": \"STOP\",\n            \"avgLogprobs\": -0.37210798559721953\n        }\n    ],\n    \"usageMetadata\": {\n        \"promptTokenCount\": 8,\n        \"candidatesTokenCount\": 644,\n        \"totalTokenCount\": 652,\n        \"promptTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 8\n            }\n        ],\n        \"candidatesTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 644\n            }\n        ]\n    },\n    \"modelVersion\": \"gemini-1.5-flash\",\n    \"responseId\": \"gzFmaJOfC57_2PgP9tmQsAc\"\n}"
						},
						{
							"name": "High topP value (1.0)",
							"originalRequest": {
								"method": "POST",
								"header": [],
								"body": {
									"mode": "raw",
									"raw": "// The purpose of topP is to change how the model selects tokens for output.\r\n// Tokens are selected from the most to least probable until the sum of their probabilities equals the topP value.\r\n// Lower topP (e.g., 0.3) = More focused, deterministic responses.\r\n// Higher topP (e.g., 0.9) = More diverse, creative responses.\r\n// Default topP value is 0.95, but here we use 0.8 for a balance between focus and creativity.\r\n{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Write a story about a magic backpack.\"\r\n                } // Request JSON payload\r\n            ]\r\n        }\r\n    ],\r\n    \"generationConfig\": {\r\n        \"topP\": {{topP}} // Adjusts response diversity\r\n    }\r\n}",
									"options": {
										"raw": {
											"language": "json"
										}
									}
								},
								"url": {
									"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
									"protocol": "https",
									"host": [
										"{{host}}"
									],
									"path": [
										"{{version}}",
										"models",
										"{{model}}:generateContent"
									]
								}
							},
							"status": "OK",
							"code": 200,
							"_postman_previewlanguage": "json",
							"header": [
								{
									"key": "Content-Type",
									"value": "application/json; charset=UTF-8"
								},
								{
									"key": "Vary",
									"value": "Origin"
								},
								{
									"key": "Vary",
									"value": "X-Origin"
								},
								{
									"key": "Vary",
									"value": "Referer"
								},
								{
									"key": "Content-Encoding",
									"value": "gzip"
								},
								{
									"key": "Date",
									"value": "Thu, 03 Jul 2025 07:31:01 GMT"
								},
								{
									"key": "Server",
									"value": "scaffolding on HTTPServer2"
								},
								{
									"key": "X-XSS-Protection",
									"value": "0"
								},
								{
									"key": "X-Frame-Options",
									"value": "SAMEORIGIN"
								},
								{
									"key": "X-Content-Type-Options",
									"value": "nosniff"
								},
								{
									"key": "Server-Timing",
									"value": "gfet4t7; dur=4630"
								},
								{
									"key": "Alt-Svc",
									"value": "h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000"
								},
								{
									"key": "Transfer-Encoding",
									"value": "chunked"
								}
							],
							"cookie": [],
							"body": "{\n    \"candidates\": [\n        {\n            \"content\": {\n                \"parts\": [\n                    {\n                        \"text\": \"Elara clutched the worn leather straps of the backpack, its faded crimson a stark contrast to the grey, slate-stone buildings surrounding her.  She’d found it abandoned in a dusty attic, tucked behind a moth-eaten tapestry. It wasn't particularly beautiful, nor was it exceptionally large, but something about its quiet, ancient hum had drawn her in.\\n\\nThat hum, she discovered, was the secret to its magic.\\n\\nThe first time she used it, she needed pencils for her art class.  She thought, \\\"Pencils,\\\" and *poof*, a box of perfectly sharpened graphite pencils materialized inside.  Next, it was a forgotten library book, a particularly tricky physics problem she'd been struggling with.  She pictured the book, its title and author clear in her mind, and there it was, pages crisp and unmarked.\\n\\nWord about Elara's miraculous backpack spread through her school like wildfire. Soon, requests began pouring in.  A lost hamster?  Inside the backpack it appeared, healthy and slightly disgruntled.  A forgotten birthday gift for her best friend Liam?  A gleaming silver locket nestled amongst perfectly-folded origami cranes materialized, reflecting the light from above.\\n\\nBut Elara quickly learned the backpack held limitations.  She couldn't conjure living creatures from scratch, just retrieve ones that were lost or misplaced.  And the more she asked, the more tired the backpack seemed to become, the crimson fading further until it was nearly brown.\\n\\nOne day, Liam approached Elara, his face etched with worry. His grandmother, a renowned botanist, had lost a rare, almost extinct orchid.  It was the last of its kind, and its loss could devastate her.  Liam pleaded with Elara to use the backpack, his eyes shining with a desperate hope.\\n\\nElara hesitated.  The backpack felt heavy, the hum almost a whisper now.  She knew that this would push it to its limits.  She visualised the orchid, its delicate petals, the vibrant shade of its bloom, its unique leaf pattern.  She focused all her energy, all her hope, into the thought.\\n\\nThe backpack pulsed with a faint, almost imperceptible glow.  Then, slowly, agonizingly slowly, a single, perfect bloom appeared inside. Its petals, impossibly delicate, unfurled, their vibrant hues radiating into the room.\\n\\nAs Elara carefully withdrew the orchid, a deep weariness settled on her. The backpack was almost lifeless, the leather dull and lifeless. The hum had ceased entirely. It seemed the magic was fully spent.  Overcome with a mixture of relief and sadness, Elara vowed to never overuse its power in the future.\\n\\nShe decided to keep the backpack, a testament to its extraordinary, limited powers.  It was no longer a source of endless wonders, but a reminder of the responsibility that came with even the smallest amount of magic, and a beautiful story, whispered only to Liam, of the time magic found its way into their world.\\n\"\n                    }\n                ],\n                \"role\": \"model\"\n            },\n            \"finishReason\": \"STOP\",\n            \"avgLogprobs\": -0.87974521136167949\n        }\n    ],\n    \"usageMetadata\": {\n        \"promptTokenCount\": 8,\n        \"candidatesTokenCount\": 617,\n        \"totalTokenCount\": 625,\n        \"promptTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 8\n            }\n        ],\n        \"candidatesTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 617\n            }\n        ]\n    },\n    \"modelVersion\": \"gemini-1.5-flash\",\n    \"responseId\": \"sTFmaI2tDZ7_2PgP9tmQsAc\"\n}"
						}
					]
				},
				{
					"name": "top_k variation",
					"request": {
						"method": "POST",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": "// The purpose of topK is to change how the model selects tokens for output.\r\n// topK of 3 means that the next token is selected from among the 3 most probable using the temperature\r\n{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Write a story about a magic backpack.\"\r\n                } // Request JSON payload\r\n            ]\r\n        }\r\n    ],\r\n    \"generationConfig\": {\r\n        \"topK\": {{topK}} // Controls token selection\r\n    }\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"{{version}}",
								"models",
								"{{model}}:generateContent"
							]
						},
						"description": "# Purpose\n\n`topK` changes how the model selects tokens for output. A `topK` of 1 means the selected token is the most probable among all the tokens in the model's vocabulary, while a `topK` of 3 means that the next token is selected from among the 3 most probable using the temperature. Tokens are further filtered based on `topP` with the final token selected using temperature sampling.\n\n# Expected Behaviour\n\n| **`topK`** **value** | **Expected Behaviour** |\n| --- | --- |\n| 1 - 10 | The model picks the most probable token from a very limited set.Responses are highly deterministic. The same prompt produces consistent output.Best for structured, factual, and instruction-based content. |\n| 20 - 50 | The model chooses from a broader selection of words, increasing variation.  <br>Responses balance coherence and creativity.  <br>Best for natural conversation, chatbots, and informative writing |\n| 100 - 200 | The model selects from a much wider range of words, making responses more diverse.  <br>Responses become less predictable, potentially more imaginative but also less structured.  <br>Best for storytelling, creative writing, and brainstorming. |"
					},
					"response": [
						{
							"name": "Low topK value (10)",
							"originalRequest": {
								"method": "POST",
								"header": [],
								"body": {
									"mode": "raw",
									"raw": "// The purpose of topK is to change how the model selects tokens for output.\r\n// topK of 3 means that the next token is selected from among the 3 most probabl using the temperature\r\n{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Write a story about a magic backpack.\"\r\n                } // Request JSON payload\r\n            ]\r\n        }\r\n    ],\r\n    \"generationConfig\": {\r\n        \"topK\": {{topK}} // Controls token selection\r\n    }\r\n}",
									"options": {
										"raw": {
											"language": "json"
										}
									}
								},
								"url": {
									"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
									"protocol": "https",
									"host": [
										"{{host}}"
									],
									"path": [
										"{{version}}",
										"models",
										"{{model}}:generateContent"
									]
								}
							},
							"status": "OK",
							"code": 200,
							"_postman_previewlanguage": "json",
							"header": [
								{
									"key": "Content-Type",
									"value": "application/json; charset=UTF-8"
								},
								{
									"key": "Vary",
									"value": "Origin"
								},
								{
									"key": "Vary",
									"value": "X-Origin"
								},
								{
									"key": "Vary",
									"value": "Referer"
								},
								{
									"key": "Content-Encoding",
									"value": "gzip"
								},
								{
									"key": "Date",
									"value": "Thu, 03 Jul 2025 07:32:11 GMT"
								},
								{
									"key": "Server",
									"value": "scaffolding on HTTPServer2"
								},
								{
									"key": "X-XSS-Protection",
									"value": "0"
								},
								{
									"key": "X-Frame-Options",
									"value": "SAMEORIGIN"
								},
								{
									"key": "X-Content-Type-Options",
									"value": "nosniff"
								},
								{
									"key": "Server-Timing",
									"value": "gfet4t7; dur=4810"
								},
								{
									"key": "Alt-Svc",
									"value": "h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000"
								},
								{
									"key": "Transfer-Encoding",
									"value": "chunked"
								}
							],
							"cookie": [],
							"body": "{\n    \"candidates\": [\n        {\n            \"content\": {\n                \"parts\": [\n                    {\n                        \"text\": \"Elara clutched the worn leather straps of the backpack, its faded emerald green hinting at a history older than her grandmother.  She’d found it tucked away in the attic, nestled amongst moth-eaten quilts and forgotten toys.  It wasn't just old; it felt… alive.\\n\\nThe first sign was the smell – a faint, intoxicating blend of pine needles, sea salt, and something indefinably magical.  Then, as she zipped it open, a cascade of shimmering, iridescent dust spilled out, settling like tiny, joyful stars on the dusty attic floor.  Inside, the backpack was surprisingly spacious, larger than its external dimensions suggested.\\n\\nThat night, Elara packed it for a camping trip with her friend Finn.  She added a tent, sleeping bag, and some trail mix, but curiously, the backpack felt lighter than it should.  When they arrived at their campsite, a gust of wind unexpectedly whipped through the trees, and Elara, rummaging for her water bottle, found a gleaming thermos instead, filled with steaming hot cocoa.  The cocoa wasn't on her packing list.\\n\\nThe next day, they were hiking, the trail winding upwards through a dense forest.  Finn tripped, his ankle twisting painfully.  Elara, panicked, reached into her backpack for a first-aid kit. Instead, she pulled out a small, intricately carved wooden box.  Inside, nestled on a bed of velvet, lay a perfect, shimmering moonstone.  As she placed it on Finn’s injured ankle, a soothing warmth spread through the area, and the pain vanished.\\n\\nOver the next few days, the backpack continued to surprise them.  A sudden downpour brought forth a waterproof tarp, appearing as if from thin air.  A hungry pang was answered with a basket overflowing with juicy berries and warm bread.  It seemed to anticipate their every need, adapting its contents to the situation.\\n\\nBut the backpack's magic wasn't without its quirks.  One evening, Elara reached for her map, only to pull out a squawking parrot wearing a tiny monocle.  Another time, a perfectly formed miniature replica of the Eiffel Tower emerged, causing Finn to howl with laughter.  The backpack's surprises were unpredictable, a chaotic symphony of useful and utterly bizarre items.\\n\\nAs they packed up to leave, Elara felt a pang of sadness.  The backpack, more than just a convenient container, had become a companion on their adventure.  She slipped her hand into its depths, and this time, it wasn't a practical item that emerged, but a small, smooth stone, warm to the touch.  It felt like a thank you, a memory of the magical journey they’d shared.\\n\\nThe backpack's magic faded over time, its contents reverting to the mundane.  But Elara kept it, the emerald green leather now even more faded, a tangible reminder of the extraordinary adventures that had sprung from a seemingly ordinary, magical backpack.  The small, smooth stone, however, remained perpetually warm in her pocket, a silent promise of more unexpected wonders to come.\\n\"\n                    }\n                ],\n                \"role\": \"model\"\n            },\n            \"finishReason\": \"STOP\",\n            \"avgLogprobs\": -0.51472634764103875\n        }\n    ],\n    \"usageMetadata\": {\n        \"promptTokenCount\": 8,\n        \"candidatesTokenCount\": 642,\n        \"totalTokenCount\": 650,\n        \"promptTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 8\n            }\n        ],\n        \"candidatesTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 642\n            }\n        ]\n    },\n    \"modelVersion\": \"gemini-1.5-flash\",\n    \"responseId\": \"9zFmaNv1D-OTmecPk9OkiAs\"\n}"
						},
						{
							"name": "Medium topK value (50)",
							"originalRequest": {
								"method": "POST",
								"header": [],
								"body": {
									"mode": "raw",
									"raw": "// The purpose of topK is to change how the model selects tokens for output.\r\n// topK of 3 means that the next token is selected from among the 3 most probable using the temperature\r\n{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Write a story about a magic backpack.\"\r\n                } // Request JSON payload\r\n            ]\r\n        }\r\n    ],\r\n    \"generationConfig\": {\r\n        \"topK\": {{topK}} // Controls token selection\r\n    }\r\n}",
									"options": {
										"raw": {
											"language": "json"
										}
									}
								},
								"url": {
									"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
									"protocol": "https",
									"host": [
										"{{host}}"
									],
									"path": [
										"{{version}}",
										"models",
										"{{model}}:generateContent"
									]
								}
							},
							"status": "OK",
							"code": 200,
							"_postman_previewlanguage": "json",
							"header": [
								{
									"key": "Content-Type",
									"value": "application/json; charset=UTF-8"
								},
								{
									"key": "Vary",
									"value": "Origin"
								},
								{
									"key": "Vary",
									"value": "X-Origin"
								},
								{
									"key": "Vary",
									"value": "Referer"
								},
								{
									"key": "Content-Encoding",
									"value": "gzip"
								},
								{
									"key": "Date",
									"value": "Thu, 03 Jul 2025 07:32:50 GMT"
								},
								{
									"key": "Server",
									"value": "scaffolding on HTTPServer2"
								},
								{
									"key": "X-XSS-Protection",
									"value": "0"
								},
								{
									"key": "X-Frame-Options",
									"value": "SAMEORIGIN"
								},
								{
									"key": "X-Content-Type-Options",
									"value": "nosniff"
								},
								{
									"key": "Server-Timing",
									"value": "gfet4t7; dur=5046"
								},
								{
									"key": "Alt-Svc",
									"value": "h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000"
								},
								{
									"key": "Transfer-Encoding",
									"value": "chunked"
								}
							],
							"cookie": [],
							"body": "{\n    \"candidates\": [\n        {\n            \"content\": {\n                \"parts\": [\n                    {\n                        \"text\": \"Elara wasn't expecting a magic backpack.  She’d expected a boring, beige, canvas thing for her hiking trip with her grumpy grandfather, not a shimmering, midnight-blue satchel that seemed to hum with barely-contained energy.  Grandpa, bless his crotchety heart, had simply presented it, a twinkle in his usually-unblinking eye.  \\\"A little something,\\\" he'd mumbled, \\\"for the journey.\\\"\\n\\nThe journey was supposed to be a week-long trek through the Whispering Woods, a place Grandpa claimed held more secrets than the library of Alexandria.  Elara, a city girl, was less than thrilled.  The first day was unremarkable, the backpack surprisingly comfortable, even when carrying her hefty load.  But on the second day, as a sudden downpour threatened to soak them to the bone, Elara rummaged inside for her rain poncho.  Instead, she pulled out… a perfectly dry, fluffy, yellow raincoat.\\n\\nGrandpa, watching her with a smirk, explained, \\\"It anticipates your needs, child.  Quite useful in a place as unpredictable as the Whispering Woods.\\\"\\n\\nThe following days were a testament to the backpack's uncanny abilities.  A seemingly endless supply of perfectly ripe berries appeared when they needed sustenance.  A sturdy, magically-appearing rope rescued them from a treacherous ravine.  A miniature, self-folding tent popped out when night fell.  Even a first-aid kit materialized when Elara scraped her knee.\\n\\nElara, initially skeptical, began to rely on the magic backpack completely.  But the deeper they went into the woods, the more she sensed a subtle unease.  The backpack, while helpful, seemed to subtly guide them, leading them down paths Grandpa hadn’t planned.  The humming intensified, becoming a low thrum that vibrated through her bones.\\n\\nOne evening, as they camped near a hidden waterfall, Grandpa finally revealed the truth. The backpack wasn’t just any magic item; it was a guardian, tasked with protecting a hidden grove sacred to the Whispering Woods.  It had chosen Elara, sensing her kind heart, to lead her – and unwittingly, Grandpa – to its location.\\n\\nThe grove was a breathtaking spectacle, filled with glowing flora and creatures she’d only read about in fairy tales.  But it was threatened.  A creeping blight, a dark magic, was slowly consuming its life force.  The backpack pulsed with light, urging Elara to help.\\n\\nElara, armed with nothing but her wit and the backpack's seemingly endless resources, spent the next few days battling the blight.  She used the backpack's magical tools – shimmering dust to heal the plants, tiny, glowing creatures to fight off the encroaching darkness – to restore the grove to its former glory.\\n\\nWhen the last tendril of the blight withered, the backpack glowed brightly, then dimmed, its magic seemingly spent.  It returned to being an ordinary, if somewhat worn, blue satchel.  But Elara felt no disappointment.  She had experienced magic, not just in the form of a wondrous backpack, but in the power of kindness and courage.  And as she and Grandpa walked out of the woods, hand-in-hand, she knew that the true magic lay not in the enchanted object, but in the journey it had helped them share.\\n\"\n                    }\n                ],\n                \"role\": \"model\"\n            },\n            \"finishReason\": \"STOP\",\n            \"avgLogprobs\": -0.55880860076553518\n        }\n    ],\n    \"usageMetadata\": {\n        \"promptTokenCount\": 8,\n        \"candidatesTokenCount\": 696,\n        \"totalTokenCount\": 704,\n        \"promptTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 8\n            }\n        ],\n        \"candidatesTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 696\n            }\n        ]\n    },\n    \"modelVersion\": \"gemini-1.5-flash\",\n    \"responseId\": \"HTJmaNSAO5CQm9IPgImIiQU\"\n}"
						},
						{
							"name": "High topK value (200)",
							"originalRequest": {
								"method": "POST",
								"header": [],
								"body": {
									"mode": "raw",
									"raw": "// The purpose of topK is to change how the model selects tokens for output.\r\n// topK of 3 means that the next token is selected from among the 3 most probable using the temperature\r\n{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Write a story about a magic backpack.\"\r\n                } // Request JSON payload\r\n            ]\r\n        }\r\n    ],\r\n    \"generationConfig\": {\r\n        \"topK\": {{topK}} // Controls token selection\r\n    }\r\n}",
									"options": {
										"raw": {
											"language": "json"
										}
									}
								},
								"url": {
									"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
									"protocol": "https",
									"host": [
										"{{host}}"
									],
									"path": [
										"{{version}}",
										"models",
										"{{model}}:generateContent"
									]
								}
							},
							"status": "OK",
							"code": 200,
							"_postman_previewlanguage": "json",
							"header": [
								{
									"key": "Content-Type",
									"value": "application/json; charset=UTF-8"
								},
								{
									"key": "Vary",
									"value": "Origin"
								},
								{
									"key": "Vary",
									"value": "X-Origin"
								},
								{
									"key": "Vary",
									"value": "Referer"
								},
								{
									"key": "Content-Encoding",
									"value": "gzip"
								},
								{
									"key": "Date",
									"value": "Thu, 03 Jul 2025 07:33:43 GMT"
								},
								{
									"key": "Server",
									"value": "scaffolding on HTTPServer2"
								},
								{
									"key": "X-XSS-Protection",
									"value": "0"
								},
								{
									"key": "X-Frame-Options",
									"value": "SAMEORIGIN"
								},
								{
									"key": "X-Content-Type-Options",
									"value": "nosniff"
								},
								{
									"key": "Server-Timing",
									"value": "gfet4t7; dur=4573"
								},
								{
									"key": "Alt-Svc",
									"value": "h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000"
								},
								{
									"key": "Transfer-Encoding",
									"value": "chunked"
								}
							],
							"cookie": [],
							"body": "{\n    \"candidates\": [\n        {\n            \"content\": {\n                \"parts\": [\n                    {\n                        \"text\": \"Elara wasn't your typical twelve-year-old.  While other kids obsessed over pop stars and social media, Elara dreamed of adventure.  So, when her eccentric Great-Aunt Millie passed away, leaving her a battered, leather backpack, Elara felt a surge of something more than just sadness; it was anticipation.\\n\\nThe backpack was unremarkable at first glance, smelling faintly of woodsmoke and old books. But then, as Elara zipped it open, a gust of warm, spiced air rushed out, carrying the scent of cinnamon and pine needles. Inside, nestled amongst a faded map and a tarnished compass, lay a single, perfectly ripe mango.  Elara, who’d had toast for breakfast, devoured it instantly.  It tasted like sunshine and summer holidays.\\n\\nThe next day, feeling bolder, Elara packed her schoolbooks into the magic backpack.  When she arrived at school, her history textbook was mysteriously replaced by a first-hand account of the Roman conquest of Britain, penned on parchment and smelling faintly of charcoal.  Her math textbook had transformed into a set of enchanted abacuses that solved equations with a satisfying click.\\n\\nWord spread. Soon, Elara’s backpack was the talk of the school.  Some whispered of magic, others of elaborate pranks.  But Elara knew.  She could ask the backpack for anything –  a specific book, a tool, even a snack – and it would appear.  It seemed to anticipate her needs, even before she knew them herself.\\n\\nOne day, Elara’s best friend, Leo, confessed that he'd been having trouble with his grandfather, a renowned but reclusive sculptor who’d fallen into a deep depression.  Elara, remembering the map inside the backpack, felt a surge of hope.\\n\\nThat night, she asked the backpack for help.  The next morning, the backpack contained not just a tool kit, but also a small, clay bird, perfectly sculpted, the detail so fine it seemed almost alive.  She knew it was a message, an offering from her grandfather, channeled somehow through the magic of the bag.\\n\\nFollowing the faded map, Elara and Leo found their way to a hidden studio nestled deep within the woods.  Leo's grandfather, frail but with a spark rekindled in his eyes, was amazed by the clay bird.  It was a style he'd abandoned years ago, a style that only he could recognize.\\n\\nThe reunion was emotional, but it was the backpack that brokered it.  It hadn’t simply provided a tool or a clue, it had facilitated a connection, healing the rift between Leo and his grandfather.\\n\\nElara understood then the true power of the magic backpack. It wasn’t about acquiring material things, but about fostering connections and solving problems.  It was a catalyst for adventure, yes, but more importantly, it was a conduit for kindness and understanding.  And that, she realized, was a far greater adventure than any she could have imagined.\\n\"\n                    }\n                ],\n                \"role\": \"model\"\n            },\n            \"finishReason\": \"STOP\",\n            \"avgLogprobs\": -0.62016904296875\n        }\n    ],\n    \"usageMetadata\": {\n        \"promptTokenCount\": 8,\n        \"candidatesTokenCount\": 625,\n        \"totalTokenCount\": 633,\n        \"promptTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 8\n            }\n        ],\n        \"candidatesTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 625\n            }\n        ]\n    },\n    \"modelVersion\": \"gemini-1.5-flash\",\n    \"responseId\": \"UzJmaLnTHvS2ld8P_KPZiAU\"\n}"
						}
					]
				},
				{
					"name": "temperature variation",
					"request": {
						"method": "POST",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Explain how AI works\"\r\n                }\r\n            ]\r\n        }\r\n    ],\r\n    \"generationConfig\": {\r\n        \"temperature\": {{temperature}}\r\n    }\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"{{version}}",
								"models",
								"{{model}}:generateContent"
							]
						},
						"description": "# Purpose\n\n`temperature` controls the randomness of the output. Use higher values for more creative responses, and lower values for more deterministic responses. Values can range from \\[0.0, 2.0\\].it's purpose is to change the response according to the requirements and level of creative response.\n\n# Expected Behaviour\n\nsample input request JSON\n\n``` json\n{\n        \"contents\": [{\n            \"parts\":[\n                {\"text\": \"Describe a futuristic city in 2 lines\"} // Request JSON payload\n            ]\n        }],\n        \"generationConfig\": {\n            \"temperature\": {{temperature}} // Controls randomness\n        }\n}\n\n ```\n\nExpected output response\n\n| **temperature value** | **expected response** |\n| --- | --- |\n| 0.2 | Gleaming chrome towers pierced a sky perpetually twilight, their shadows falling on streets where hovercars zipped between bioluminescent gardens. Beneath, a network of subterranean tunnels pulsed with the city's unseen lifeblood. |\n| 0.7 | Gleaming chrome towers pierce a perpetually twilight sky, their shadows cast upon streets humming with autonomous vehicles and holographic advertisements. Below, bioluminescent flora illuminates pathways winding through verdant, vertical farms |\n| 1.0 | Gleaming chrome towers pierced a sky perpetually bathed in neon, while autonomous vehicles zipped silently through levitating roadways. Below, citizens blended seamlessly with holographic advertisements and bioluminescent flora |"
					},
					"response": [
						{
							"name": "Low Temperature Value (0.2)",
							"originalRequest": {
								"method": "POST",
								"header": [],
								"body": {
									"mode": "raw",
									"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Explain how AI works\"\r\n                }\r\n            ]\r\n        }\r\n    ],\r\n    \"generationConfig\": {\r\n        \"temperature\": {{temperature}}\r\n    }\r\n}",
									"options": {
										"raw": {
											"language": "json"
										}
									}
								},
								"url": {
									"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
									"protocol": "https",
									"host": [
										"{{host}}"
									],
									"path": [
										"{{version}}",
										"models",
										"{{model}}:generateContent"
									]
								}
							},
							"status": "OK",
							"code": 200,
							"_postman_previewlanguage": "json",
							"header": [
								{
									"key": "Content-Type",
									"value": "application/json; charset=UTF-8"
								},
								{
									"key": "Vary",
									"value": "Origin"
								},
								{
									"key": "Vary",
									"value": "X-Origin"
								},
								{
									"key": "Vary",
									"value": "Referer"
								},
								{
									"key": "Content-Encoding",
									"value": "gzip"
								},
								{
									"key": "Date",
									"value": "Thu, 03 Jul 2025 07:35:15 GMT"
								},
								{
									"key": "Server",
									"value": "scaffolding on HTTPServer2"
								},
								{
									"key": "X-XSS-Protection",
									"value": "0"
								},
								{
									"key": "X-Frame-Options",
									"value": "SAMEORIGIN"
								},
								{
									"key": "X-Content-Type-Options",
									"value": "nosniff"
								},
								{
									"key": "Server-Timing",
									"value": "gfet4t7; dur=6277"
								},
								{
									"key": "Alt-Svc",
									"value": "h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000"
								},
								{
									"key": "Transfer-Encoding",
									"value": "chunked"
								}
							],
							"cookie": [],
							"body": "{\n    \"candidates\": [\n        {\n            \"content\": {\n                \"parts\": [\n                    {\n                        \"text\": \"Artificial intelligence (AI) is a broad field encompassing many techniques, but at its core, it's about creating systems that can perform tasks that typically require human intelligence.  These tasks include things like learning, reasoning, problem-solving, perception, and natural language understanding.  There's no single \\\"how it works\\\" answer, as different AI approaches use different methods.  However, we can break it down into key concepts:\\n\\n**1. Data is King:**  AI systems learn from data.  The more relevant and high-quality data they're trained on, the better they perform. This data can be anything from images and text to sensor readings and financial transactions.\\n\\n**2. Algorithms are the Engine:**  Algorithms are sets of rules and statistical techniques that AI systems use to process data and learn patterns.  These algorithms are the \\\"brains\\\" of the system, determining how it analyzes information and makes decisions.  Different algorithms are suited for different tasks.\\n\\n**3. Learning Paradigms:**  There are several ways AI systems learn:\\n\\n* **Supervised Learning:** The AI is trained on a labeled dataset, meaning the data is already tagged with the correct answers.  The algorithm learns to map inputs to outputs based on these examples.  Think of teaching a dog tricks – you show them what to do and reward them for correct behavior.  Examples include image classification (identifying objects in pictures) and spam detection.\\n\\n* **Unsupervised Learning:** The AI is trained on an unlabeled dataset.  The algorithm's job is to find patterns and structures in the data without explicit guidance.  This is like asking a child to sort toys based on their similarities – they figure out the categories themselves.  Examples include clustering (grouping similar data points) and dimensionality reduction (simplifying complex data).\\n\\n* **Reinforcement Learning:** The AI learns through trial and error by interacting with an environment.  It receives rewards for desirable actions and penalties for undesirable ones.  This is like training a robot to navigate a maze – it learns by trying different paths and getting rewarded for reaching the goal.  Examples include game playing (AlphaGo) and robotics control.\\n\\n**4. Models are the Representation:**  During the learning process, the AI system creates a model that represents the patterns and relationships it has learned from the data.  This model can be a complex mathematical equation, a neural network, or another type of representation.  The model is what allows the AI to make predictions or decisions on new, unseen data.\\n\\n**5. Neural Networks (a common approach):**  Neural networks are a type of algorithm inspired by the structure and function of the human brain.  They consist of interconnected nodes (neurons) organized in layers.  Information flows through the network, and the connections between nodes are adjusted during training to improve the network's performance.  Deep learning uses very deep neural networks with many layers to learn complex patterns.\\n\\n**In short:** AI systems learn from data using algorithms to create models that can perform intelligent tasks.  The specific techniques used depend on the task and the type of data available.  While the field is complex, the fundamental principles revolve around learning from data and using that learning to make predictions or decisions.\\n\"\n                    }\n                ],\n                \"role\": \"model\"\n            },\n            \"finishReason\": \"STOP\",\n            \"avgLogprobs\": -0.12346383749720562\n        }\n    ],\n    \"usageMetadata\": {\n        \"promptTokenCount\": 4,\n        \"candidatesTokenCount\": 664,\n        \"totalTokenCount\": 668,\n        \"promptTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 4\n            }\n        ],\n        \"candidatesTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 664\n            }\n        ]\n    },\n    \"modelVersion\": \"gemini-1.5-flash\",\n    \"responseId\": \"rzJmaJaGFPysnvgPrcy4iAg\"\n}"
						},
						{
							"name": "Medium Temperature value (0.7)",
							"originalRequest": {
								"method": "POST",
								"header": [],
								"body": {
									"mode": "raw",
									"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Explain how AI works\"\r\n                }\r\n            ]\r\n        }\r\n    ],\r\n    \"generationConfig\": {\r\n        \"temperature\": {{temperature}}\r\n    }\r\n}",
									"options": {
										"raw": {
											"language": "json"
										}
									}
								},
								"url": {
									"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
									"protocol": "https",
									"host": [
										"{{host}}"
									],
									"path": [
										"{{version}}",
										"models",
										"{{model}}:generateContent"
									]
								}
							},
							"status": "OK",
							"code": 200,
							"_postman_previewlanguage": "json",
							"header": [
								{
									"key": "Content-Type",
									"value": "application/json; charset=UTF-8"
								},
								{
									"key": "Vary",
									"value": "Origin"
								},
								{
									"key": "Vary",
									"value": "X-Origin"
								},
								{
									"key": "Vary",
									"value": "Referer"
								},
								{
									"key": "Content-Encoding",
									"value": "gzip"
								},
								{
									"key": "Date",
									"value": "Thu, 03 Jul 2025 07:36:16 GMT"
								},
								{
									"key": "Server",
									"value": "scaffolding on HTTPServer2"
								},
								{
									"key": "X-XSS-Protection",
									"value": "0"
								},
								{
									"key": "X-Frame-Options",
									"value": "SAMEORIGIN"
								},
								{
									"key": "X-Content-Type-Options",
									"value": "nosniff"
								},
								{
									"key": "Server-Timing",
									"value": "gfet4t7; dur=6524"
								},
								{
									"key": "Alt-Svc",
									"value": "h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000"
								},
								{
									"key": "Transfer-Encoding",
									"value": "chunked"
								}
							],
							"cookie": [],
							"body": "{\n    \"candidates\": [\n        {\n            \"content\": {\n                \"parts\": [\n                    {\n                        \"text\": \"Artificial intelligence (AI) is a broad field encompassing many techniques, but at its core, it aims to create systems that can perform tasks that typically require human intelligence.  These tasks include things like learning, reasoning, problem-solving, perception, and language understanding.  There's no single \\\"how it works\\\" answer, as different AI approaches use different methods. However, we can break it down into key concepts:\\n\\n**1. Data is King:**  AI systems learn from data.  The more relevant and high-quality data they're trained on, the better they perform.  This data can be anything from images and text to sensor readings and financial transactions.\\n\\n**2. Algorithms are the Engine:**  Algorithms are sets of rules and statistical techniques that AI systems use to process data and learn patterns.  These algorithms are the \\\"brains\\\" of the system, determining how it learns, makes decisions, and solves problems.  Different algorithms are suited for different tasks.  Some common types include:\\n\\n* **Machine Learning (ML):**  This is a subset of AI where systems learn from data without explicit programming.  Instead of being explicitly told what to do, they identify patterns and make predictions based on the data they've seen.  There are several types of ML, including:\\n    * **Supervised Learning:** The algorithm is trained on labeled data (e.g., images labeled as \\\"cat\\\" or \\\"dog\\\").  It learns to map inputs to outputs based on these labels.\\n    * **Unsupervised Learning:** The algorithm is trained on unlabeled data and tries to find structure or patterns in the data on its own (e.g., clustering similar data points together).\\n    * **Reinforcement Learning:** The algorithm learns through trial and error by interacting with an environment. It receives rewards for good actions and penalties for bad actions, learning to maximize its reward over time.\\n\\n* **Deep Learning (DL):** A subfield of ML that uses artificial neural networks with multiple layers (hence \\\"deep\\\").  These networks are inspired by the structure and function of the human brain and can learn complex patterns from vast amounts of data.  Deep learning is particularly powerful for tasks like image recognition, natural language processing, and speech recognition.\\n\\n* **Expert Systems:** These AI systems are based on rules and knowledge provided by human experts.  They use these rules to make decisions and solve problems in a specific domain.\\n\\n\\n**3. Models are the Output:** After training on data using chosen algorithms, the AI system creates a \\\"model.\\\" This model is a representation of the patterns and relationships learned from the data.  It's what the AI uses to make predictions or decisions on new, unseen data.\\n\\n**4. Evaluation and Iteration:** AI systems are constantly evaluated to measure their performance.  This involves testing the model on new data and comparing its predictions to the actual results.  Based on this evaluation, the system may be retrained or improved to enhance its accuracy and efficiency.  This iterative process is crucial for refining AI systems and making them more robust.\\n\\n\\nIn short, AI works by combining data, algorithms, and computational power to create models that can learn from data, make predictions, and solve problems.  The specific techniques used depend on the task and the available data.  The field is constantly evolving, with new algorithms and approaches being developed all the time.\\n\"\n                    }\n                ],\n                \"role\": \"model\"\n            },\n            \"finishReason\": \"STOP\",\n            \"avgLogprobs\": -0.13815491206364261\n        }\n    ],\n    \"usageMetadata\": {\n        \"promptTokenCount\": 4,\n        \"candidatesTokenCount\": 694,\n        \"totalTokenCount\": 698,\n        \"promptTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 4\n            }\n        ],\n        \"candidatesTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 694\n            }\n        ]\n    },\n    \"modelVersion\": \"gemini-1.5-flash\",\n    \"responseId\": \"6zJmaLeOKY3H2PgP3czb4Ao\"\n}"
						},
						{
							"name": "High Temperature value (1.0)",
							"originalRequest": {
								"method": "POST",
								"header": [],
								"body": {
									"mode": "raw",
									"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Explain how AI works\"\r\n                }\r\n            ]\r\n        }\r\n    ],\r\n    \"generationConfig\": {\r\n        \"temperature\": {{temperature}}\r\n    }\r\n}",
									"options": {
										"raw": {
											"language": "json"
										}
									}
								},
								"url": {
									"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
									"protocol": "https",
									"host": [
										"{{host}}"
									],
									"path": [
										"{{version}}",
										"models",
										"{{model}}:generateContent"
									]
								}
							},
							"status": "OK",
							"code": 200,
							"_postman_previewlanguage": "json",
							"header": [
								{
									"key": "Content-Type",
									"value": "application/json; charset=UTF-8"
								},
								{
									"key": "Vary",
									"value": "Origin"
								},
								{
									"key": "Vary",
									"value": "X-Origin"
								},
								{
									"key": "Vary",
									"value": "Referer"
								},
								{
									"key": "Content-Encoding",
									"value": "gzip"
								},
								{
									"key": "Date",
									"value": "Thu, 03 Jul 2025 07:37:03 GMT"
								},
								{
									"key": "Server",
									"value": "scaffolding on HTTPServer2"
								},
								{
									"key": "X-XSS-Protection",
									"value": "0"
								},
								{
									"key": "X-Frame-Options",
									"value": "SAMEORIGIN"
								},
								{
									"key": "X-Content-Type-Options",
									"value": "nosniff"
								},
								{
									"key": "Server-Timing",
									"value": "gfet4t7; dur=5173"
								},
								{
									"key": "Alt-Svc",
									"value": "h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000"
								},
								{
									"key": "Transfer-Encoding",
									"value": "chunked"
								}
							],
							"cookie": [],
							"body": "{\n    \"candidates\": [\n        {\n            \"content\": {\n                \"parts\": [\n                    {\n                        \"text\": \"AI doesn't work in a single, unified way.  Instead, it encompasses a broad range of techniques and approaches, all aiming to mimic aspects of human intelligence.  However, we can break down how many AI systems function into these key components:\\n\\n**1. Data:**  AI systems learn from data.  The more relevant and high-quality data they are trained on, the better they perform. This data can be anything from images and text to sensor readings and financial transactions.\\n\\n**2. Algorithms:** These are the sets of rules and calculations that the AI uses to process the data.  Different AI techniques use different algorithms.  Some common types include:\\n\\n* **Machine Learning (ML):** This is a core component of many AI systems.  Instead of being explicitly programmed, ML algorithms learn patterns and relationships from data.  They improve their performance over time through experience (exposure to more data).  Key types of ML include:\\n    * **Supervised Learning:** The algorithm is trained on labeled data (data where the correct answer is already known).  For example, showing an image classifier many pictures of cats and dogs, labeled accordingly.\\n    * **Unsupervised Learning:** The algorithm is trained on unlabeled data and tries to find patterns and structure on its own.  For example, clustering similar customers together based on their purchase history.\\n    * **Reinforcement Learning:** The algorithm learns through trial and error, receiving rewards for correct actions and penalties for incorrect ones.  This is often used in robotics and game playing.\\n\\n* **Deep Learning (DL):** A subset of ML that uses artificial neural networks with multiple layers (hence \\\"deep\\\").  These networks are inspired by the structure and function of the human brain.  Deep learning excels at tasks involving complex patterns and large amounts of data, such as image recognition, natural language processing, and speech recognition.\\n\\n* **Expert Systems:** These systems mimic the decision-making ability of a human expert in a specific domain.  They use a set of rules and knowledge bases to arrive at conclusions.\\n\\n**3. Model:**  The algorithm, after being trained on the data, creates a \\\"model.\\\" This model is a representation of the patterns and relationships learned from the data.  It's what the AI uses to make predictions or decisions on new, unseen data.\\n\\n**4. Inference/Prediction:** Once a model is trained, it can be used to make inferences or predictions on new data.  This is the stage where the AI actually performs its task, like classifying an image, translating text, or recommending a product.\\n\\n**5. Evaluation:** The performance of the AI system is constantly evaluated to identify areas for improvement.  This involves measuring the accuracy, precision, and other relevant metrics of the model's predictions.\\n\\n\\n**In Simple Terms:** Imagine teaching a dog a trick.  The data is the many times you show the dog the trick and reward it for doing it correctly. The algorithm is the method of training (positive reinforcement). The model is the dog's learned behavior. Inference is the dog performing the trick when you ask. Evaluation is assessing how well the dog learned the trick.\\n\\nIt's crucial to remember that AI systems are tools.  Their capabilities are defined by the data they are trained on, the algorithms they use, and the way they are designed and implemented.  They are not inherently conscious or sentient, but they can perform complex tasks that previously required human intelligence.\\n\"\n                    }\n                ],\n                \"role\": \"model\"\n            },\n            \"finishReason\": \"STOP\",\n            \"avgLogprobs\": -0.19969957330253688\n        }\n    ],\n    \"usageMetadata\": {\n        \"promptTokenCount\": 4,\n        \"candidatesTokenCount\": 712,\n        \"totalTokenCount\": 716,\n        \"promptTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 4\n            }\n        ],\n        \"candidatesTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 712\n            }\n        ]\n    },\n    \"modelVersion\": \"gemini-1.5-flash\",\n    \"responseId\": \"GjNmaJ_WN86BnvgPyLjriQ0\"\n}"
						}
					]
				},
				{
					"name": "stopSequences variation",
					"request": {
						"method": "POST",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": "// stopSequences - specifies the set of character sequences (up to 5) that will stop output generation\r\n// The stop sequence won't be included as part of the response.\r\n{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Write a story about a magic backpack.\"\r\n                } // Request JSON payload\r\n            ]\r\n        }\r\n    ],\r\n    \"generationConfig\": {\r\n        \"stopSequences\": [\r\n            \"{{character}}\"\r\n        ]\r\n    }\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"{{version}}",
								"models",
								"{{model}}:generateContent"
							]
						},
						"description": "# Purpose\n\n`stopSequences` specifies the set of character sequences (up to 5) that will stop output generation. If specified, the API will stop at the first appearance of a `stop_sequence`. The stop sequence won't be included as part of the response.\n\n# Expected Behaviour\n\n``` json\n{\n        \"contents\": [{\n            \"parts\":[\n                {\"text\": \"Write a story about a magic backpack.\"} // Request JSON payload\n            ]\n        }],\n        \"generationConfig\": {\n            \"stopSequences\":[\n                \"{{character}}\"\n            ]\n        }\n}\n\n ```\n\nExpected response (character = \"magic\" )\n\n``` json\n{\n    \"candidates\": [\n        {\n            \"content\": {\n                \"parts\": [\n                    {\n                        \"text\": \"Elara wasn't your typical twelve-year-old. While other kids obsessed over pop stars and social media, Elara dreamt of faraway lands and forgotten histories.  Her dream took a decidedly literal turn the day she found it: a worn, leather \"\n                    }\n                ],\n                \"role\": \"model\"\n            },\n            \"finishReason\": \"STOP\",\n            \"avgLogprobs\": -5.7647722032335071\n        }\n    ],\n    \"usageMetadata\": {\n        \"promptTokenCount\": 8,\n        \"candidatesTokenCount\": 54,\n        \"totalTokenCount\": 62,\n        \"promptTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 8\n            }\n        ],\n        \"candidatesTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 54\n            }\n        ]\n    },\n    \"modelVersion\": \"gemini-1.5-flash\"\n}\n\n ```"
					},
					"response": [
						{
							"name": "stopSequences variation",
							"originalRequest": {
								"method": "POST",
								"header": [],
								"body": {
									"mode": "raw",
									"raw": "// stopSequences - specifies the set of character sequences (up to 5) that will stop output generation\r\n// The stop sequence won't be included as part of the response.\r\n{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Write a story about a magic backpack.\"\r\n                } // Request JSON payload\r\n            ]\r\n        }\r\n    ],\r\n    \"generationConfig\": {\r\n        \"stopSequences\": [\r\n            \"{{character}}\"\r\n        ]\r\n    }\r\n}",
									"options": {
										"raw": {
											"language": "json"
										}
									}
								},
								"url": {
									"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
									"protocol": "https",
									"host": [
										"{{host}}"
									],
									"path": [
										"{{version}}",
										"models",
										"{{model}}:generateContent"
									]
								}
							},
							"status": "OK",
							"code": 200,
							"_postman_previewlanguage": "json",
							"header": [
								{
									"key": "Content-Type",
									"value": "application/json; charset=UTF-8"
								},
								{
									"key": "Vary",
									"value": "Origin"
								},
								{
									"key": "Vary",
									"value": "X-Origin"
								},
								{
									"key": "Vary",
									"value": "Referer"
								},
								{
									"key": "Content-Encoding",
									"value": "gzip"
								},
								{
									"key": "Date",
									"value": "Thu, 03 Jul 2025 07:38:16 GMT"
								},
								{
									"key": "Server",
									"value": "scaffolding on HTTPServer2"
								},
								{
									"key": "X-XSS-Protection",
									"value": "0"
								},
								{
									"key": "X-Frame-Options",
									"value": "SAMEORIGIN"
								},
								{
									"key": "X-Content-Type-Options",
									"value": "nosniff"
								},
								{
									"key": "Server-Timing",
									"value": "gfet4t7; dur=822"
								},
								{
									"key": "Alt-Svc",
									"value": "h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000"
								},
								{
									"key": "Transfer-Encoding",
									"value": "chunked"
								}
							],
							"cookie": [],
							"body": "{\n    \"candidates\": [\n        {\n            \"content\": {\n                \"parts\": [\n                    {\n                        \"text\": \"Elara wasn't your typical twelve-year-old.  While her peers obsessed over pop stars and social media, Elara dreamt of faraway lands and forgotten lore. So when her eccentric Great-Aunt Millie bequeathed her a worn leather \"\n                    }\n                ],\n                \"role\": \"model\"\n            },\n            \"finishReason\": \"STOP\",\n            \"avgLogprobs\": -0.34203475952148438\n        }\n    ],\n    \"usageMetadata\": {\n        \"promptTokenCount\": 8,\n        \"candidatesTokenCount\": 50,\n        \"totalTokenCount\": 58,\n        \"promptTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 8\n            }\n        ],\n        \"candidatesTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 50\n            }\n        ]\n    },\n    \"modelVersion\": \"gemini-1.5-flash\",\n    \"responseId\": \"ZzNmaLneOOScmecPrM3gqQ4\"\n}"
						}
					]
				},
				{
					"name": "maxOutputTokens variation",
					"request": {
						"method": "POST",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": "// sets the maximum number of tokens to include in a candidate.\r\n{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Describe a futuristic city\"\r\n                } // Request JSON payload\r\n            ]\r\n        }\r\n    ],\r\n    \"generationConfig\": {\r\n        \"maxOutputTokens\": {{maxOutputTokens}}// Limits response length\r\n    }\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"{{version}}",
								"models",
								"{{model}}:generateContent"
							]
						},
						"description": "# Purpose\n\n`maxOutputTokens` sets the maximum number of tokens to include in a candidate.\n\n# Expected Behaviour\n\nIf the value of maxOutputToken is less , then the output response length will also be short and if the maxOutputToken value is high then the output will be of larger length.\n\ninput - Describe a futuristic city.\n\n| **maxOutputTokens** | **Expected Behaviour** |\n| --- | --- |\n| 20 | Aeon City sprawls across a series of interconnected, bioluminescent towers that pierce a perpetually twilight |\n| 100 | Anya City hummed with a silent energy. Skyscrapers, sleek and bioluminescent, pierced the perpetually twilight sky, their surfaces shifting colours in a mesmerizing, coordinated dance programmed by central AI. Flying vehicles, more like iridescent dragonfly swarms than clunky machines, zipped between the buildings, their paths a complex ballet choreographed by a city-wide traffic management system. The streets below were largely pedestrianized, vibrant oases of vertical farms and shimmering holographic advertisements that reacted to passersby |"
					},
					"response": [
						{
							"name": "maxOutputTokens variation",
							"originalRequest": {
								"method": "POST",
								"header": [],
								"body": {
									"mode": "raw",
									"raw": "// sets the maximum number of tokens to include in a candidate.\r\n{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Describe a futuristic city\"\r\n                } // Request JSON payload\r\n            ]\r\n        }\r\n    ],\r\n    \"generationConfig\": {\r\n        \"maxOutputTokens\": {{maxOutputTokens}}// Limits response length\r\n    }\r\n}",
									"options": {
										"raw": {
											"language": "json"
										}
									}
								},
								"url": {
									"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
									"protocol": "https",
									"host": [
										"{{host}}"
									],
									"path": [
										"{{version}}",
										"models",
										"{{model}}:generateContent"
									]
								}
							},
							"status": "OK",
							"code": 200,
							"_postman_previewlanguage": "json",
							"header": [
								{
									"key": "Content-Type",
									"value": "application/json; charset=UTF-8"
								},
								{
									"key": "Vary",
									"value": "Origin"
								},
								{
									"key": "Vary",
									"value": "X-Origin"
								},
								{
									"key": "Vary",
									"value": "Referer"
								},
								{
									"key": "Content-Encoding",
									"value": "gzip"
								},
								{
									"key": "Date",
									"value": "Thu, 03 Jul 2025 07:39:17 GMT"
								},
								{
									"key": "Server",
									"value": "scaffolding on HTTPServer2"
								},
								{
									"key": "X-XSS-Protection",
									"value": "0"
								},
								{
									"key": "X-Frame-Options",
									"value": "SAMEORIGIN"
								},
								{
									"key": "X-Content-Type-Options",
									"value": "nosniff"
								},
								{
									"key": "Server-Timing",
									"value": "gfet4t7; dur=2955"
								},
								{
									"key": "Alt-Svc",
									"value": "h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000"
								},
								{
									"key": "Transfer-Encoding",
									"value": "chunked"
								}
							],
							"cookie": [],
							"body": "{\n    \"candidates\": [\n        {\n            \"content\": {\n                \"parts\": [\n                    {\n                        \"text\": \"Neo-Kyoto hummed with a silent energy. Towering structures, crafted from polished obsidian and shimmering bioluminescent alloys, scraped the perpetually twilight sky, their forms mimicking the elegant curves of ancient pagodas yet scaled to impossible heights.  Hovercars, sleek and silent, zipped between the buildings, their paths illuminated by interwoven holographic pathways that shifted and reformed with the city's dynamic flow.\\n\\nBelow the sky-piercing towers, sprawling vertical farms pulsed with emerald and sapphire light, their hydroponic systems a constant, rhythmic heartbeat in the cityscape.  Elevated walkways, lined with holographic advertisements that shimmered and shifted with the viewer's perspective, connected the different levels, weaving a complex network of interconnected spaces.  Citizens, clad in sleek, adaptive clothing that changed color and texture with their mood, moved with a fluid grace, a blend of human and technological integration.\\n\\nThe air, purified by advanced atmospheric processors, was crisp and clean, tinged with the scent of blossoming synthetic cherry trees lining the lower levels.  Robots, indistinguishable from humans in many cases, seamlessly integrated into the urban fabric, performing tasks from waste management to advanced medical care.  Drones, tiny and efficient, buzzed silently, delivering packages and monitoring the city's intricate systems.\\n\\nNeo-Kyoto wasn't just a city; it was a living, breathing organism.  Its infrastructure was a symphony of interconnected systems, constantly adapting and evolving, fueled by renewable energy sources and guided by a sophisticated AI that managed every aspect of urban life with graceful efficiency.  Yet, amidst the technological marvel, pockets of traditional Japanese culture persisted – serene gardens nestled amongst towering skyscrapers, tea ceremonies held in minimalist holographic environments, and the whisper of ancient traditions woven into the futuristic tapestry.  It was a city where the past and the future co-existed in a harmonious, breathtaking embrace.\\n\"\n                    }\n                ],\n                \"role\": \"model\"\n            },\n            \"finishReason\": \"STOP\",\n            \"avgLogprobs\": -0.56451773136220085\n        }\n    ],\n    \"usageMetadata\": {\n        \"promptTokenCount\": 4,\n        \"candidatesTokenCount\": 376,\n        \"totalTokenCount\": 380,\n        \"promptTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 4\n            }\n        ],\n        \"candidatesTokensDetails\": [\n            {\n                \"modality\": \"TEXT\",\n                \"tokenCount\": 376\n            }\n        ]\n    },\n    \"modelVersion\": \"gemini-1.5-flash\",\n    \"responseId\": \"ojNmaKrKLNugmecPwYihoAc\"\n}"
						}
					]
				}
			]
		},
		{
			"name": "Image Generation",
			"item": [
				{
					"name": "Text-and-image-to-image",
					"item": [
						{
							"name": "1.Get the Upload Url",
							"event": [
								{
									"listen": "test",
									"script": {
										"exec": [
											"let upload_url_header = pm.response.headers.get(\"x-goog-upload-url\"); // Get the upload URL from the response headers\r",
											"if (upload_url_header){\r",
											"pm.environment.set(\"upload_url_image\", upload_url_header);\r",
											"}\r",
											"else{\r",
											"    console.log(\"Unable to get the upload url , check the API KEY or Gemini-Testing environment variables value\")\r",
											"}"
										],
										"type": "text/javascript",
										"packages": {}
									}
								}
							],
							"request": {
								"method": "POST",
								"header": [
									{
										"key": "X-Goog-Upload-Command",
										"value": "start",
										"type": "text"
									},
									{
										"key": "X-Goog-Upload-Header-Content-Type",
										"value": "{{MIME_TYPE}}",
										"type": "text"
									},
									{
										"key": "X-Goog-Upload-Protocol",
										"value": "resumable",
										"type": "text"
									}
								],
								"body": {
									"mode": "raw",
									"raw": "{\r\n    \"file\": {\r\n        \"display_name\": \"{{Display_Name}}\"\r\n    }\r\n}",
									"options": {
										"raw": {
											"language": "json"
										}
									}
								},
								"url": {
									"raw": "https://{{host}}/upload/{{version}}/files",
									"protocol": "https",
									"host": [
										"{{host}}"
									],
									"path": [
										"upload",
										"{{version}}",
										"files"
									]
								}
							},
							"response": []
						},
						{
							"name": "2.Upload The Image",
							"event": [
								{
									"listen": "test",
									"script": {
										"exec": [
											"const response = pm.response.json();\r",
											"if(response.file.uri){\r",
											"    pm.environment.set(\"file_uri_image\",response.file.uri);\r",
											"}\r",
											"else{\r",
											"    console.log(\"Unable to get the file_uri_image, kindly check the audio uploaded ,upload_url_video and the headers\")\r",
											"}"
										],
										"type": "text/javascript",
										"packages": {}
									}
								}
							],
							"request": {
								"method": "POST",
								"header": [
									{
										"key": "X-Goog-Upload-Offset",
										"value": "0",
										"type": "text"
									},
									{
										"key": "X-Goog-Upload-Command",
										"value": "upload, finalize",
										"type": "text"
									}
								],
								"body": {
									"mode": "file",
									"file": {
										"src": ""
									}
								},
								"url": {
									"raw": "{{upload_url_image}}",
									"host": [
										"{{upload_url_image}}"
									]
								}
							},
							"response": []
						},
						{
							"name": "3.Generate Content",
							"request": {
								"method": "POST",
								"header": [],
								"body": {
									"mode": "raw",
									"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"'Hi, This is a picture of me. Can you add a llama next to me\"\r\n                },\r\n                {\r\n                    \"inline_data\": {\r\n                        \"mime_type\": \"{{MIME_TYPE}}\",\r\n                        \"data\": {{file_uri_image}}\r\n                    }\r\n                }\r\n            ]\r\n        }\r\n    ],\r\n    \"generationConfig\": {\r\n        \"responseModalities\": [\r\n            \"TEXT\",\r\n            \"IMAGE\"\r\n        ]\r\n    }\r\n}",
									"options": {
										"raw": {
											"language": "json"
										}
									}
								}
							},
							"response": []
						}
					]
				},
				{
					"name": "text-to-image",
					"request": {
						"method": "POST",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Hi, can you create a 3d rendered image of a pig with wings and a top hat flying over a happy futuristic scifi city with lots of greenery?\"\r\n                }\r\n            ]\r\n        }\r\n    ],\r\n    \"generationConfig\": {\r\n        \"responseModalities\": [\r\n            \"TEXT\",\r\n            \"IMAGE\"\r\n        ]\r\n    }\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"{{version}}",
								"models",
								"{{model}}:generateContent"
							]
						}
					},
					"response": []
				},
				{
					"name": "Generate Image using Imagen 3",
					"request": {
						"method": "POST",
						"header": [
							{
								"key": "X-Goog-Upload-Command",
								"value": "start",
								"type": "text"
							},
							{
								"key": "X-Goog-Upload-Header-Content-Type",
								"value": "{{MIME_TYPE}}",
								"type": "text"
							},
							{
								"key": "X-Goog-Upload-Protocol",
								"value": "resumable",
								"type": "text"
							}
						],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"instances\": [\r\n        {\r\n            \"prompt\": \"Robot holding a red skateboard\"\r\n        }\r\n    ],\r\n    \"parameters\": {\r\n        \"sampleCount\": 4\r\n    }\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/{{version}}/models/{{model}}:predict",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"{{version}}",
								"models",
								"{{model}}:predict"
							]
						}
					},
					"response": []
				}
			]
		},
		{
			"name": "Video Generation",
			"item": [
				{
					"name": "Generate video using Veo",
					"request": {
						"method": "POST",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"instances\": [\r\n        {\r\n            \"prompt\": \"Panning wide shot of a calico kitten sleeping in the sunshine\"\r\n        }\r\n    ],\r\n    \"parameters\": {\r\n        \"aspectRatio\": \"16:9\",\r\n        \"personGeneration\": \"dont_allow\"\r\n    }\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/{{version}}/models/{{model}}:predictLongRunning",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"{{version}}",
								"models",
								"{{model}}:predictLongRunning"
							]
						}
					},
					"response": []
				}
			]
		},
		{
			"name": "Speech Generation",
			"item": [
				{
					"name": "Single-speaker text-to-speech",
					"request": {
						"method": "POST",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Say cheerfully: Have a wonderful day!\"\r\n                }\r\n            ]\r\n        }\r\n    ],\r\n    \"generationConfig\": {\r\n        \"responseModalities\": [\r\n            \"AUDIO\"\r\n        ],\r\n        \"speechConfig\": {\r\n            \"voiceConfig\": {\r\n                \"prebuiltVoiceConfig\": {\r\n                    \"voiceName\": \"Kore\"\r\n                }\r\n            }\r\n        }\r\n    },\r\n    \"model\": \"gemini-2.5-flash-preview-tts\"\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"{{version}}",
								"models",
								"{{model}}:generateContent"
							]
						}
					},
					"response": []
				},
				{
					"name": "Multi-speaker text-to-speech",
					"request": {
						"method": "POST",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"TTS the following conversation between Joe and Jane: Joe: Hows it going today Jane Jane: Not too bad, how about you?\"\r\n                }\r\n            ]\r\n        }\r\n    ],\r\n    \"generationConfig\": {\r\n        \"responseModalities\": [\r\n            \"AUDIO\"\r\n        ],\r\n        \"speechConfig\": {\r\n            \"multiSpeakerVoiceConfig\": {\r\n                \"speakerVoiceConfigs\": [\r\n                    {\r\n                        \"speaker\": \"Joe\",\r\n                        \"voiceConfig\": {\r\n                            \"prebuiltVoiceConfig\": {\r\n                                \"voiceName\": \"Kore\"\r\n                            }\r\n                        }\r\n                    },\r\n                    {\r\n                        \"speaker\": \"Jane\",\r\n                        \"voiceConfig\": {\r\n                            \"prebuiltVoiceConfig\": {\r\n                                \"voiceName\": \"Puck\"\r\n                            }\r\n                        }\r\n                    }\r\n                ]\r\n            }\r\n        }\r\n    },\r\n    \"model\": \"gemini-2.5-flash-preview-tts\"\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"{{version}}",
								"models",
								"{{model}}:generateContent"
							]
						}
					},
					"response": []
				}
			]
		},
		{
			"name": "Structured Output",
			"item": [
				{
					"name": "Configuring a schema",
					"event": [
						{
							"listen": "test",
							"script": {
								"exec": [
									""
								],
								"type": "text/javascript",
								"packages": {}
							}
						}
					],
					"request": {
						"method": "POST",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"List a few popular cookie recipes, and include the amounts of ingredients.\"\r\n                }\r\n            ]\r\n        }\r\n    ],\r\n    \"generationConfig\": {\r\n        \"responseMimeType\": \"application/json\",\r\n        \"responseSchema\": {\r\n            \"type\": \"ARRAY\",\r\n            \"items\": {\r\n                \"type\": \"OBJECT\",\r\n                \"properties\": {\r\n                    \"recipeName\": {\r\n                        \"type\": \"STRING\"\r\n                    },\r\n                    \"ingredients\": {\r\n                        \"type\": \"ARRAY\",\r\n                        \"items\": {\r\n                            \"type\": \"STRING\"\r\n                        }\r\n                    }\r\n                },\r\n                \"propertyOrdering\": [\r\n                    \"recipeName\",\r\n                    \"ingredients\"\r\n                ]\r\n            }\r\n        }\r\n    }\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"{{version}}",
								"models",
								"{{model}}:generateContent"
							]
						}
					},
					"response": []
				}
			]
		},
		{
			"name": "Thinking",
			"item": [
				{
					"name": "Generating content with thinking",
					"request": {
						"method": "POST",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Explain the concept of Occam's Razor and provide a simple, everyday example.\"\r\n                }\r\n            ]\r\n        }\r\n    ]\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"{{version}}",
								"models",
								"{{model}}:generateContent"
							]
						}
					},
					"response": []
				},
				{
					"name": "Thinking budgets",
					"request": {
						"method": "POST",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Provide a list of 3 famous physicists and their key contributions\"\r\n                }\r\n            ]\r\n        }\r\n    ],\r\n    \"generationConfig\": {\r\n        \"thinkingConfig\": {\r\n            \"thinkingBudget\": 1024\r\n        //Thinking off:\r\n         //\"thinkingBudget\": 0\r\n         //Turn on dynamic thinking:\r\n         //\"thinkingBudget\": -1\r\n        }\r\n    }\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"{{version}}",
								"models",
								"{{model}}:generateContent"
							]
						}
					},
					"response": []
				}
			]
		},
		{
			"name": "Function Calling",
			"item": [
				{
					"name": "Schedule Meeting",
					"request": {
						"method": "POST",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"role\": \"user\",\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Schedule a meeting with Bob and Alice for 03/27/2025 at 10:00 AM about the Q3 planning.\"\r\n                }\r\n            ]\r\n        }\r\n    ],\r\n    \"tools\": [\r\n        {\r\n            \"functionDeclarations\": [\r\n                {\r\n                    \"name\": \"schedule_meeting\",\r\n                    \"description\": \"Schedules a meeting with specified attendees at a given time and date.\",\r\n                    \"parameters\": {\r\n                        \"type\": \"object\",\r\n                        \"properties\": {\r\n                            \"attendees\": {\r\n                                \"type\": \"array\",\r\n                                \"items\": {\r\n                                    \"type\": \"string\"\r\n                                },\r\n                                \"description\": \"List of people attending the meeting.\"\r\n                            },\r\n                            \"date\": {\r\n                                \"type\": \"string\",\r\n                                \"description\": \"Date of the meeting (e.g., '2024-07-29')\"\r\n                            },\r\n                            \"time\": {\r\n                                \"type\": \"string\",\r\n                                \"description\": \"Time of the meeting (e.g., '15:00')\"\r\n                            },\r\n                            \"topic\": {\r\n                                \"type\": \"string\",\r\n                                \"description\": \"The subject or topic of the meeting.\"\r\n                            }\r\n                        },\r\n                        \"required\": [\r\n                            \"attendees\",\r\n                            \"date\",\r\n                            \"time\",\r\n                            \"topic\"\r\n                        ]\r\n                    }\r\n                }\r\n            ]\r\n        }\r\n    ]\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"{{version}}",
								"models",
								"{{model}}:generateContent"
							]
						}
					},
					"response": []
				},
				{
					"name": "Get Weather",
					"request": {
						"method": "POST",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"role\": \"user\",\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"What is the temperature in London?\"\r\n                }\r\n            ]\r\n        }\r\n    ],\r\n    \"tools\": [\r\n        {\r\n            \"functionDeclarations\": [\r\n                {\r\n                    \"name\": \"get_current_temperature\",\r\n                    \"description\": \"Gets the current temperature for a given location.\",\r\n                    \"parameters\": {\r\n                        \"type\": \"object\",\r\n                        \"properties\": {\r\n                            \"location\": {\r\n                                \"type\": \"string\",\r\n                                \"description\": \"The city name, e.g. San Francisco\"\r\n                            }\r\n                        },\r\n                        \"required\": [\r\n                            \"location\"\r\n                        ]\r\n                    }\r\n                }\r\n            ]\r\n        }\r\n    ]\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"{{version}}",
								"models",
								"{{model}}:generateContent"
							]
						}
					},
					"response": []
				},
				{
					"name": "Create Chart",
					"request": {
						"method": "POST",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"role\": \"user\",\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Create a bar chart titled Quarterly Sales with data: Q1: 50000, Q2: 75000, Q3: 60000.\"\r\n                }\r\n            ]\r\n        }\r\n    ],\r\n    \"tools\": [\r\n        {\r\n            \"functionDeclarations\": [\r\n                {\r\n                    \"name\": \"create_bar_chart\",\r\n                    \"description\": \"Creates a bar chart given a title, labels, and corresponding values.\",\r\n                    \"parameters\": {\r\n                        \"type\": \"object\",\r\n                        \"properties\": {\r\n                            \"title\": {\r\n                                \"type\": \"string\",\r\n                                \"description\": \"The title for the chart.\"\r\n                            },\r\n                            \"labels\": {\r\n                                \"type\": \"array\",\r\n                                \"items\": {\r\n                                    \"type\": \"string\"\r\n                                },\r\n                                \"description\": \"List of labels for the data points (e.g.[Q1, Q2, Q3]).\"\r\n                            },\r\n                            \"values\": {\r\n                                \"type\": \"array\",\r\n                                \"items\": {\r\n                                    \"type\": \"number\"\r\n                                },\r\n                                \"description\": \"List of numerical values corresponding to the labels (e.g., [50000, 75000, 60000]).\"\r\n                            }\r\n                        },\r\n                        \"required\": [\r\n                            \"title\",\r\n                            \"labels\",\r\n                            \"values\"\r\n                        ]\r\n                    }\r\n                }\r\n            ]\r\n        }\r\n    ]\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"{{version}}",
								"models",
								"{{model}}:generateContent"
							]
						}
					},
					"response": []
				}
			]
		},
		{
			"name": "Document Understanding",
			"item": [
				{
					"name": "1.Get the Upload Url PDF",
					"event": [
						{
							"listen": "test",
							"script": {
								"exec": [
									"let upload_url_header = pm.response.headers.get(\"x-goog-upload-url\"); // Get the upload URL from the response headers\r",
									"if (upload_url_header){\r",
									"pm.environment.set(\"upload_url_PDF\", upload_url_header);\r",
									"}\r",
									"else{\r",
									"    console.log(\"Unable to get the upload url , check the API KEY or Gemini-Testing environment variables value\")\r",
									"}"
								],
								"type": "text/javascript",
								"packages": {}
							}
						}
					],
					"request": {
						"method": "POST",
						"header": [
							{
								"key": "X-Goog-Upload-Command",
								"value": "start",
								"type": "text"
							},
							{
								"key": "X-Goog-Upload-Header-Content-Type",
								"value": "{{MIME_TYPE}}",
								"type": "text"
							},
							{
								"key": "X-Goog-Upload-Protocol",
								"value": "resumable",
								"type": "text"
							}
						],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"file\": {\r\n        \"display_name\": \"{{Display_Name_PDF}}\"\r\n    }\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/upload/{{version}}/files",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"upload",
								"{{version}}",
								"files"
							]
						}
					},
					"response": []
				},
				{
					"name": "2.Upload The PDF",
					"event": [
						{
							"listen": "test",
							"script": {
								"exec": [
									"const response = pm.response.json();\r",
									"if(response.file.uri){\r",
									"    pm.environment.set(\"file_uri_PDF\",response.file.uri);\r",
									"}\r",
									"else{\r",
									"    console.log(\"Unable to get the file_uri_PDF, kindly check the audio uploaded ,upload_url_video and the headers\")\r",
									"}"
								],
								"type": "text/javascript",
								"packages": {}
							}
						}
					],
					"request": {
						"method": "POST",
						"header": [
							{
								"key": "X-Goog-Upload-Offset",
								"value": "0",
								"type": "text"
							},
							{
								"key": "X-Goog-Upload-Command",
								"value": "upload, finalize",
								"type": "text"
							}
						],
						"body": {
							"mode": "file",
							"file": {
								"src": ""
							}
						},
						"url": {
							"raw": "{{upload_url_PDF}}",
							"host": [
								"{{upload_url_PDF}}"
							]
						}
					},
					"response": []
				},
				{
					"name": "3.Generate Content",
					"request": {
						"method": "POST",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"'Hi, This is a picture of me. Can you add a llama next to me\"\r\n                },\r\n                {\r\n                    \"inline_data\": {\r\n                        \"mime_type\": \"{{MIME_TYPE}}\",\r\n                        \"data\": {{file_uri_PDF}}\r\n                    }\r\n                }\r\n            ]\r\n        }\r\n    ],\r\n    \"generationConfig\": {\r\n        \"responseModalities\": [\r\n            \"TEXT\",\r\n            \"IMAGE\"\r\n        ]\r\n    }\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						}
					},
					"response": []
				}
			]
		},
		{
			"name": "Image Understanding",
			"item": [
				{
					"name": "1.Get the Upload Url",
					"event": [
						{
							"listen": "test",
							"script": {
								"exec": [
									"let upload_url_header = pm.response.headers.get(\"x-goog-upload-url\"); // Get the upload URL from the response headers\r",
									"if (upload_url_header){\r",
									"pm.environment.set(\"upload_url_image\", upload_url_header);\r",
									"}\r",
									"else{\r",
									"    console.log(\"Unable to get the upload url , check the API KEY or Gemini-Testing environment variables value\")\r",
									"}"
								],
								"type": "text/javascript",
								"packages": {}
							}
						}
					],
					"request": {
						"method": "POST",
						"header": [
							{
								"key": "X-Goog-Upload-Command",
								"value": "start",
								"type": "text"
							},
							{
								"key": "X-Goog-Upload-Header-Content-Type",
								"value": "{{MIME_TYPE}}",
								"type": "text"
							},
							{
								"key": "X-Goog-Upload-Protocol",
								"value": "resumable",
								"type": "text"
							}
						],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"file\": {\r\n        \"display_name\": \"{{Display_Name}}\"\r\n    }\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/upload/{{version}}/files",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"upload",
								"{{version}}",
								"files"
							]
						}
					},
					"response": []
				},
				{
					"name": "2.Upload The Image",
					"event": [
						{
							"listen": "test",
							"script": {
								"exec": [
									"const response = pm.response.json();\r",
									"if(response.file.uri){\r",
									"    pm.environment.set(\"file_uri_image\",response.file.uri);\r",
									"}\r",
									"else{\r",
									"    console.log(\"Unable to get the file_uri_image, kindly check the audio uploaded ,upload_url_video and the headers\")\r",
									"}"
								],
								"type": "text/javascript",
								"packages": {}
							}
						}
					],
					"request": {
						"method": "POST",
						"header": [
							{
								"key": "X-Goog-Upload-Offset",
								"value": "0",
								"type": "text"
							},
							{
								"key": "X-Goog-Upload-Command",
								"value": "upload, finalize",
								"type": "text"
							}
						],
						"body": {
							"mode": "file",
							"file": {
								"src": ""
							}
						},
						"url": {
							"raw": "{{upload_url_image}}",
							"host": [
								"{{upload_url_image}}"
							]
						}
					},
					"response": []
				},
				{
					"name": "3.Generate Content",
					"request": {
						"method": "POST",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Caption this image\"\r\n                },\r\n                {\r\n                    \"inline_data\": {\r\n                        \"mime_type\": \"{{MIME_TYPE}}\",\r\n                        \"data\": {{file_uri_image}}\r\n                    }\r\n                }\r\n            ]\r\n        }\r\n    ],\r\n    \"generationConfig\": {\r\n        \"responseModalities\": [\r\n            \"TEXT\",\r\n            \"IMAGE\"\r\n        ]\r\n    }\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						}
					},
					"response": []
				}
			]
		},
		{
			"name": "Video Understanding",
			"item": [
				{
					"name": "1.Get the Upload Url Video",
					"event": [
						{
							"listen": "test",
							"script": {
								"exec": [
									"let upload_url_header = pm.response.headers.get(\"x-goog-upload-url\"); // Get the upload URL from the response headers\r",
									"if (upload_url_header){\r",
									"pm.environment.set(\"upload_url_image\", upload_url_header);\r",
									"}\r",
									"else{\r",
									"    console.log(\"Unable to get the upload url , check the API KEY or Gemini-Testing environment variables value\")\r",
									"}"
								],
								"type": "text/javascript",
								"packages": {}
							}
						}
					],
					"request": {
						"method": "POST",
						"header": [
							{
								"key": "X-Goog-Upload-Command",
								"value": "start",
								"type": "text"
							},
							{
								"key": "X-Goog-Upload-Header-Content-Type",
								"value": "{{MIME_TYPE}}",
								"type": "text"
							},
							{
								"key": "X-Goog-Upload-Protocol",
								"value": "resumable",
								"type": "text"
							}
						],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"file\": {\r\n        \"display_name\": \"{{Display_Name_Video}}\"\r\n    }\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/upload/{{version}}/files",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"upload",
								"{{version}}",
								"files"
							]
						}
					},
					"response": []
				},
				{
					"name": "2.Upload The Video",
					"event": [
						{
							"listen": "test",
							"script": {
								"exec": [
									"const response = pm.response.json();\r",
									"if(response.file.uri){\r",
									"    pm.environment.set(\"file_uri_video\",response.file.uri);\r",
									"}\r",
									"else{\r",
									"    console.log(\"Unable to get the file_uri_video, kindly check the audio uploaded ,upload_url_video and the headers\")\r",
									"}"
								],
								"type": "text/javascript",
								"packages": {}
							}
						}
					],
					"request": {
						"method": "POST",
						"header": [
							{
								"key": "X-Goog-Upload-Offset",
								"value": "0",
								"type": "text"
							},
							{
								"key": "X-Goog-Upload-Command",
								"value": "upload, finalize",
								"type": "text"
							}
						],
						"body": {
							"mode": "file",
							"file": {
								"src": ""
							}
						},
						"url": {
							"raw": "{{upload_url_image}}",
							"host": [
								"{{upload_url_image}}"
							]
						}
					},
					"response": []
				},
				{
					"name": "3.Generate Content",
					"request": {
						"method": "POST",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Summarize this video. Then create a quiz with an answer key based on the information in this video.\"\r\n                },\r\n                {\r\n                    \"inline_data\": {\r\n                        \"mime_type\": \"{{MIME_TYPE}}\",\r\n                        \"data\": {{file_uri_video}}\r\n                    }\r\n                }\r\n            ]\r\n        }\r\n    ],\r\n    \"generationConfig\": {\r\n        \"responseModalities\": [\r\n            \"TEXT\",\r\n            \"IMAGE\"\r\n        ]\r\n    }\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						}
					},
					"response": []
				}
			]
		},
		{
			"name": "Audio Understanding",
			"item": [
				{
					"name": "1.Get the Upload Url Audio",
					"event": [
						{
							"listen": "test",
							"script": {
								"exec": [
									"let upload_url_header = pm.response.headers.get(\"x-goog-upload-url\"); // Get the upload URL from the response headers\r",
									"if (upload_url_header){\r",
									"pm.environment.set(\"upload_url_audio\", upload_url_header);\r",
									"}\r",
									"else{\r",
									"    console.log(\"Unable to get the upload url , check the API KEY or Gemini-Testing environment variables value\")\r",
									"}"
								],
								"type": "text/javascript",
								"packages": {}
							}
						}
					],
					"request": {
						"method": "POST",
						"header": [
							{
								"key": "X-Goog-Upload-Command",
								"value": "start",
								"type": "text"
							},
							{
								"key": "X-Goog-Upload-Header-Content-Type",
								"value": "{{MIME_TYPE}}",
								"type": "text"
							},
							{
								"key": "X-Goog-Upload-Protocol",
								"value": "resumable",
								"type": "text"
							}
						],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"file\": {\r\n        \"display_name\": \"{{Display_Name_Video}}\"\r\n    }\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/upload/{{version}}/files",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"upload",
								"{{version}}",
								"files"
							]
						}
					},
					"response": []
				},
				{
					"name": "2.Upload The Audio",
					"event": [
						{
							"listen": "test",
							"script": {
								"exec": [
									"const response = pm.response.json();\r",
									"if(response.file.uri){\r",
									"    pm.environment.set(\"file_uri_audio\",response.file.uri);\r",
									"}\r",
									"else{\r",
									"    console.log(\"Unable to get the file_uri_audio, kindly check the audio uploaded ,upload_url_video and the headers\")\r",
									"}"
								],
								"type": "text/javascript",
								"packages": {}
							}
						}
					],
					"request": {
						"method": "POST",
						"header": [
							{
								"key": "X-Goog-Upload-Offset",
								"value": "0",
								"type": "text"
							},
							{
								"key": "X-Goog-Upload-Command",
								"value": "upload, finalize",
								"type": "text"
							}
						],
						"body": {
							"mode": "file",
							"file": {
								"src": ""
							}
						},
						"url": {
							"raw": "{{upload_url_image}}",
							"host": [
								"{{upload_url_image}}"
							]
						}
					},
					"response": []
				},
				{
					"name": "3.Generate Content",
					"request": {
						"method": "POST",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"contents\": [\r\n        {\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Summarize this video. Then create a quiz with an answer key based on the information in this video.\"\r\n                },\r\n                {\r\n                    \"inline_data\": {\r\n                        \"mime_type\": \"{{MIME_TYPE}}\",\r\n                        \"data\": {{flie_uri_audio}}\r\n                    }\r\n                }\r\n            ]\r\n        }\r\n    ],\r\n    \"generationConfig\": {\r\n        \"responseModalities\": [\r\n            \"TEXT\",\r\n            \"IMAGE\"\r\n        ]\r\n    }\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						}
					},
					"response": []
				}
			]
		},
		{
			"name": "Code Execution",
			"item": [
				{
					"name": "Enable code execution",
					"request": {
						"method": "POST",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"tools\": [\r\n        {\r\n            \"code_execution\": {}\r\n        }\r\n    ],\r\n    \"contents\": {\r\n        \"parts\": {\r\n            \"text\": \"What is the sum of the first 50 prime numbers? Generate and run code for the calculation, and make sure you get all 50.\"\r\n        }\r\n    }\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"{{version}}",
								"models",
								"{{model}}:generateContent"
							]
						}
					},
					"response": []
				},
				{
					"name": "Use code execution in chat",
					"request": {
						"method": "POST",
						"header": [],
						"body": {
							"mode": "raw",
							"raw": "{\r\n    \"tools\": [\r\n        {\r\n            \"code_execution\": {}\r\n        }\r\n    ],\r\n    \"contents\": [\r\n        {\r\n            \"role\": \"user\",\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"Can you print \\\"Hello world!\\\"?\"\r\n                }\r\n            ]\r\n        },\r\n        {\r\n            \"role\": \"model\",\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"\"\r\n                },\r\n                {\r\n                    \"executable_code\": {\r\n                        \"language\": \"PYTHON\",\r\n                        \"code\": \"\\nprint(\\\"hello world!\\\")\\n\"\r\n                    }\r\n                },\r\n                {\r\n                    \"code_execution_result\": {\r\n                        \"outcome\": \"OUTCOME_OK\",\r\n                        \"output\": \"hello world!\\n\"\r\n                    }\r\n                },\r\n                {\r\n                    \"text\": \"I have printed \\\"hello world!\\\" using the provided python code block. \\n\"\r\n                }\r\n            ]\r\n        },\r\n        {\r\n            \"role\": \"user\",\r\n            \"parts\": [\r\n                {\r\n                    \"text\": \"What is the sum of the first 50 prime numbers? Generate and run code for the calculation, and make sure you get all 50.\"\r\n                }\r\n            ]\r\n        }\r\n    ]\r\n}",
							"options": {
								"raw": {
									"language": "json"
								}
							}
						},
						"url": {
							"raw": "https://{{host}}/{{version}}/models/{{model}}:generateContent",
							"protocol": "https",
							"host": [
								"{{host}}"
							],
							"path": [
								"{{version}}",
								"models",
								"{{model}}:generateContent"
							]
						}
					},
					"response": []
				}
			]
		}
	],
	"auth": {
		"type": "apikey",
		"apikey": [
			{
				"key": "key",
				"value": "key",
				"type": "string"
			},
			{
				"key": "value",
				"value": "{{vault:api key}}",
				"type": "string"
			},
			{
				"key": "in",
				"value": "query",
				"type": "string"
			}
		]
	},
	"event": [
		{
			"listen": "prerequest",
			"script": {
				"type": "text/javascript",
				"packages": {},
				"exec": [
					""
				]
			}
		},
		{
			"listen": "test",
			"script": {
				"type": "text/javascript",
				"packages": {},
				"exec": [
					""
				]
			}
		}
	]
}